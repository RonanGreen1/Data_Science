{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas\n",
    "from sklearn.tree import DecisionTreeClassifier, export_text, plot_tree\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load the dataset\n",
    "df = pandas.read_csv(\"TempData.csv\")\n",
    "\n",
    "# Map categorical data in the 'Nationality' column to numerical values\n",
    "d = {'UK': 0, 'USA': 1, 'N': 2}\n",
    "df['Nationality'] = df['Nationality'].map(d)\n",
    "\n",
    "# Map categorical data in the 'Go' column to numerical values\n",
    "d = {'YES': 1, 'NO': 0}\n",
    "df['Go'] = df['Go'].map(d)\n",
    "\n",
    "# Define the features (input variables) and target variable\n",
    "features = ['Age', 'Experience', 'Rank', 'Nationality']  # Columns to be used as features\n",
    "X = df[features]  # Input features\n",
    "y = df['Go']  # Target variable\n",
    "\n",
    "# Initialize the decision tree classifier\n",
    "dtree = DecisionTreeClassifier()\n",
    "\n",
    "# Fit the decision tree classifier on the data\n",
    "dtree = dtree.fit(X, y)\n",
    "\n",
    "# Plot the decision tree\n",
    "plt.figure(figsize=(12, 8))  # Set the size of the plot\n",
    "plot_tree(\n",
    "    dtree, \n",
    "    feature_names=features,  # Display feature names\n",
    "    class_names=['No', 'Yes'],  # Display class names for target variable\n",
    "    filled=True,  # Fill nodes with colors representing the classes\n",
    "    rounded=True,  # Use rounded corners for the boxes\n",
    "    fontsize=10  # Set font size\n",
    ")\n",
    "plt.show()  # Show the plot\n",
    "\n",
    "# Print a textual representation of the decision tree\n",
    "print(export_text(dtree, feature_names=features))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "df = pandas.read_csv(\"poker-hand-training-true.csv\")\n",
    "\n",
    "# Define the features and target\n",
    "features = [\"S1\", \"R1\", \"S2\", \"R2\", \"S3\", \"R3\", \"S4\", \"R4\", \"S5\", \"R5\"]\n",
    "X_train = df[features]  # Features from training data\n",
    "y_train = df[\"Class\"]  # Target from training data\n",
    "\n",
    "model = DecisionTreeClassifier(random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "print(f\"Tree Depth: {model.get_depth()}\")\n",
    "print(f\"Number of Leaves: {model.get_n_leaves()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Tree Training Results\n",
    "\n",
    "### Tree Structure\n",
    "- **Tree Depth**: 30  \n",
    "  - The depth of the tree is the longest path from the root node to a leaf node.  \n",
    "  - A depth of 30 indicates that the tree has grown very deep, creating a highly detailed set of rules for classification.  \n",
    "  - While this might improve training accuracy, it can lead to **overfitting**, where the model memorizes the training data instead of generalizing patterns.\n",
    "\n",
    "- **Number of Leaves**: 9196  \n",
    "  - Leaves are the terminal nodes in the tree where predictions are made.  \n",
    "  - The tree has 9196 leaves, which suggests it has created a large number of distinct rules to classify the data.  \n",
    "  - While this level of complexity is expected for a dataset like Poker Hands (due to the many combinations of suits and ranks), it could also indicate **overfitting**.\n",
    "\n",
    "  ### Addressing Overfitting\n",
    "To prevent overfitting and improve the model's generalization ability:\n",
    "1. **Limit the Depth of the Tree**:\n",
    "   - Restrict the maximum depth of the tree to control its complexity\n",
    "\n",
    "2. **Limit the Minimum Samples per Leaf**:\n",
    "   - Set a minimum number of samples required for a leaf node\n",
    "\n",
    "3. **Prune the Tree**:\n",
    "   - Use cost-complexity pruning (`ccp_alpha`) to remove overly specific splits\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = DecisionTreeClassifier(random_state=42, min_samples_leaf=10,  max_depth=10) # Added cap on depth and minimum samples per leaf\n",
    "model.fit(X_train, y_train)\n",
    "print(f\"Tree Depth: {model.get_depth()}\")\n",
    "print(f\"Number of Leaves: {model.get_n_leaves()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
