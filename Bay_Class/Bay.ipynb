{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Author:** Ronan Green  \n",
    "**Model:** Naive Bayes Classifier  \n",
    "**Brief Description:**  \n",
    "Naive Bayes is a probabilistic classification model based on Bayes’ Theorem with the assumption that features are independent. \n",
    "\n",
    "**Note:**  \n",
    "This notebook was created by Ronan Green. A full breakdown of the findings, methodology, and references used can be found at the end of the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 8124 entries, 0 to 8123\n",
      "Data columns (total 23 columns):\n",
      " #   Column                    Non-Null Count  Dtype \n",
      "---  ------                    --------------  ----- \n",
      " 0   class                     8124 non-null   object\n",
      " 1   cap-shape                 8124 non-null   object\n",
      " 2   cap-surface               8124 non-null   object\n",
      " 3   cap-color                 8124 non-null   object\n",
      " 4   bruises                   8124 non-null   object\n",
      " 5   odor                      8124 non-null   object\n",
      " 6   gill-attachment           8124 non-null   object\n",
      " 7   gill-spacing              8124 non-null   object\n",
      " 8   gill-size                 8124 non-null   object\n",
      " 9   gill-color                8124 non-null   object\n",
      " 10  stalk-shape               8124 non-null   object\n",
      " 11  stalk-root                8124 non-null   object\n",
      " 12  stalk-surface-above-ring  8124 non-null   object\n",
      " 13  stalk-surface-below-ring  8124 non-null   object\n",
      " 14  stalk-color-above-ring    8124 non-null   object\n",
      " 15  stalk-color-below-ring    8124 non-null   object\n",
      " 16  veil-type                 8124 non-null   object\n",
      " 17  veil-color                8124 non-null   object\n",
      " 18  ring-number               8124 non-null   object\n",
      " 19  ring-type                 8124 non-null   object\n",
      " 20  spore-print-color         8124 non-null   object\n",
      " 21  population                8124 non-null   object\n",
      " 22  habitat                   8124 non-null   object\n",
      "dtypes: object(23)\n",
      "memory usage: 1.4+ MB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class</th>\n",
       "      <th>cap-shape</th>\n",
       "      <th>cap-surface</th>\n",
       "      <th>cap-color</th>\n",
       "      <th>bruises</th>\n",
       "      <th>odor</th>\n",
       "      <th>gill-attachment</th>\n",
       "      <th>gill-spacing</th>\n",
       "      <th>gill-size</th>\n",
       "      <th>gill-color</th>\n",
       "      <th>...</th>\n",
       "      <th>stalk-surface-below-ring</th>\n",
       "      <th>stalk-color-above-ring</th>\n",
       "      <th>stalk-color-below-ring</th>\n",
       "      <th>veil-type</th>\n",
       "      <th>veil-color</th>\n",
       "      <th>ring-number</th>\n",
       "      <th>ring-type</th>\n",
       "      <th>spore-print-color</th>\n",
       "      <th>population</th>\n",
       "      <th>habitat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>p</td>\n",
       "      <td>x</td>\n",
       "      <td>s</td>\n",
       "      <td>n</td>\n",
       "      <td>t</td>\n",
       "      <td>p</td>\n",
       "      <td>f</td>\n",
       "      <td>c</td>\n",
       "      <td>n</td>\n",
       "      <td>k</td>\n",
       "      <td>...</td>\n",
       "      <td>s</td>\n",
       "      <td>w</td>\n",
       "      <td>w</td>\n",
       "      <td>p</td>\n",
       "      <td>w</td>\n",
       "      <td>o</td>\n",
       "      <td>p</td>\n",
       "      <td>k</td>\n",
       "      <td>s</td>\n",
       "      <td>u</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>e</td>\n",
       "      <td>x</td>\n",
       "      <td>s</td>\n",
       "      <td>y</td>\n",
       "      <td>t</td>\n",
       "      <td>a</td>\n",
       "      <td>f</td>\n",
       "      <td>c</td>\n",
       "      <td>b</td>\n",
       "      <td>k</td>\n",
       "      <td>...</td>\n",
       "      <td>s</td>\n",
       "      <td>w</td>\n",
       "      <td>w</td>\n",
       "      <td>p</td>\n",
       "      <td>w</td>\n",
       "      <td>o</td>\n",
       "      <td>p</td>\n",
       "      <td>n</td>\n",
       "      <td>n</td>\n",
       "      <td>g</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>e</td>\n",
       "      <td>b</td>\n",
       "      <td>s</td>\n",
       "      <td>w</td>\n",
       "      <td>t</td>\n",
       "      <td>l</td>\n",
       "      <td>f</td>\n",
       "      <td>c</td>\n",
       "      <td>b</td>\n",
       "      <td>n</td>\n",
       "      <td>...</td>\n",
       "      <td>s</td>\n",
       "      <td>w</td>\n",
       "      <td>w</td>\n",
       "      <td>p</td>\n",
       "      <td>w</td>\n",
       "      <td>o</td>\n",
       "      <td>p</td>\n",
       "      <td>n</td>\n",
       "      <td>n</td>\n",
       "      <td>m</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>p</td>\n",
       "      <td>x</td>\n",
       "      <td>y</td>\n",
       "      <td>w</td>\n",
       "      <td>t</td>\n",
       "      <td>p</td>\n",
       "      <td>f</td>\n",
       "      <td>c</td>\n",
       "      <td>n</td>\n",
       "      <td>n</td>\n",
       "      <td>...</td>\n",
       "      <td>s</td>\n",
       "      <td>w</td>\n",
       "      <td>w</td>\n",
       "      <td>p</td>\n",
       "      <td>w</td>\n",
       "      <td>o</td>\n",
       "      <td>p</td>\n",
       "      <td>k</td>\n",
       "      <td>s</td>\n",
       "      <td>u</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>e</td>\n",
       "      <td>x</td>\n",
       "      <td>s</td>\n",
       "      <td>g</td>\n",
       "      <td>f</td>\n",
       "      <td>n</td>\n",
       "      <td>f</td>\n",
       "      <td>w</td>\n",
       "      <td>b</td>\n",
       "      <td>k</td>\n",
       "      <td>...</td>\n",
       "      <td>s</td>\n",
       "      <td>w</td>\n",
       "      <td>w</td>\n",
       "      <td>p</td>\n",
       "      <td>w</td>\n",
       "      <td>o</td>\n",
       "      <td>e</td>\n",
       "      <td>n</td>\n",
       "      <td>a</td>\n",
       "      <td>g</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  class cap-shape cap-surface cap-color bruises odor gill-attachment  \\\n",
       "0     p         x           s         n       t    p               f   \n",
       "1     e         x           s         y       t    a               f   \n",
       "2     e         b           s         w       t    l               f   \n",
       "3     p         x           y         w       t    p               f   \n",
       "4     e         x           s         g       f    n               f   \n",
       "\n",
       "  gill-spacing gill-size gill-color  ... stalk-surface-below-ring  \\\n",
       "0            c         n          k  ...                        s   \n",
       "1            c         b          k  ...                        s   \n",
       "2            c         b          n  ...                        s   \n",
       "3            c         n          n  ...                        s   \n",
       "4            w         b          k  ...                        s   \n",
       "\n",
       "  stalk-color-above-ring stalk-color-below-ring veil-type veil-color  \\\n",
       "0                      w                      w         p          w   \n",
       "1                      w                      w         p          w   \n",
       "2                      w                      w         p          w   \n",
       "3                      w                      w         p          w   \n",
       "4                      w                      w         p          w   \n",
       "\n",
       "  ring-number ring-type spore-print-color population habitat  \n",
       "0           o         p                 k          s       u  \n",
       "1           o         p                 n          n       g  \n",
       "2           o         p                 n          n       m  \n",
       "3           o         p                 k          s       u  \n",
       "4           o         e                 n          a       g  \n",
       "\n",
       "[5 rows x 23 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "\n",
    "# Load the dataset\n",
    "file_path = \"mushrooms.csv\"  # Adjust path if needed\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Display basic information about the dataset\n",
    "df.info()\n",
    "\n",
    "# Display the first few rows of the dataset\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Code Explanation:\n",
    "\n",
    "1. **Import pandas:** We use the `pandas` library for data handling and manipulation.\n",
    "2. **Renaming columns:** We assign shorter names to make column references.\n",
    "3. **`df.head()`:** Displays the first five rows of the dataset.\n",
    "\n",
    "---\n",
    "\n",
    "#### Why This Step?\n",
    "\n",
    "- **Load the dataset:** Import the dataset before any analysis or preprocessing can occur.\n",
    "- **Rename columns:** Long column names can slow down development and clutter the code.\n",
    "- **Inspect the first rows:** Quickly confirms whether the dataset has been read properly, ensuring we have the right structure, column headings, and data format before proceeding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "class\n",
       "0    51.797144\n",
       "1    48.202856\n",
       "Name: proportion, dtype: float64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Initialize LabelEncoder\n",
    "label_encoder = LabelEncoder()\n",
    "\n",
    "# Apply label encoding to all categorical columns\n",
    "for column in df.columns:\n",
    "    df[column] = label_encoder.fit_transform(df[column])\n",
    "\n",
    "# Display the first few rows after encoding\n",
    "df.head()\n",
    "\n",
    "# Check class distribution\n",
    "df['class'].value_counts(normalize=True) * 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Data Preprocessing (Label Encoding & Class Distribution Check)\n",
    "\n",
    "#### Code Explanation:\n",
    "1. **Label Encoding**:  \n",
    "   - All features in our dataset are categorical.\n",
    "   - Machine learning models (such as Naïve Bayes) require numerical input.\n",
    "   - `LabelEncoder()` from `sklearn.preprocessing` is used to convert categorical values into numerical values.\n",
    "\n",
    "2. **Checking Class Distribution**:\n",
    "   - The target variable (`class`) determines whether a mushroom is **edible or poisonous**.\n",
    "   - `value_counts(normalize=True) * 100` is used to calculate the percentage of each class.\n",
    "   - This helps identify if there is an **imbalance in class distribution**.\n",
    "\n",
    "#### Why This Step?\n",
    "- **Label encoding** is necessary for numerical processing.\n",
    "- **Class distribution** helps to understand if one class is dominant, which may affect model performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((6499, 22), (1625, 22), (6499,), (1625,))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Define features (X) and target variable (y)\n",
    "X = df.drop(columns=[\"class\"])  # Features (all columns except the target)\n",
    "y = df[\"class\"]  # Target (edible or poisonous)\n",
    "\n",
    "# Split the dataset into training (80%) and testing (20%) sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "# Display the shape of the training and testing sets\n",
    "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Splitting the Data\n",
    "\n",
    "#### Code Explanation:\n",
    "1. **Defining Features and Target Variable**:\n",
    "   - The **features (X)** are all columns **except \"class\"** (i.e., all independent variables).\n",
    "   - The **target variable (y)** is the \"class\" column (edible or poisonous mushrooms).\n",
    "\n",
    "2. **Splitting the Dataset**:\n",
    "   - `train_test_split()` from `sklearn.model_selection` is used to divide the dataset.\n",
    "   - **80% of the data** is used for **training** (`X_train`, `y_train`).\n",
    "   - **20% of the data** is used for **testing** (`X_test`, `y_test`).\n",
    "   - `random_state=42` ensures reproducibility.\n",
    "   - `stratify=y` maintains the **same class proportion** in both training and testing sets.\n",
    "\n",
    "#### Why This Step?\n",
    "- **Ensures the model generalises well** by evaluating it on unseen data.\n",
    "- **Prevents data leakage** by keeping training and testing separate.\n",
    "- **Stratification** helps prevent class imbalance from affecting model learning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-1 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-1 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-1 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-1 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-1 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GaussianNB()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;GaussianNB<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.naive_bayes.GaussianNB.html\">?<span>Documentation for GaussianNB</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>GaussianNB()</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "GaussianNB()"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "# Initialize the Naïve Bayes model\n",
    "nb_model = GaussianNB()\n",
    "\n",
    "# Train the model on the training data\n",
    "nb_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Training the Naïve Bayes Classifier\n",
    "\n",
    "#### Code Explanation:\n",
    "1. **Choosing the Classifier**:\n",
    "   - `GaussianNB()` from `sklearn.naive_bayes`.\n",
    "   - **Naïve Bayes assumes features are independent** given the class label.\n",
    "\n",
    "2. **Training the Model**:\n",
    "   - `.fit(X_train, y_train)` is called to train the model using the **training dataset**.\n",
    "\n",
    "#### Why This Step?\n",
    "- This step is crucial as the model learns the relationship between features and the target variable.\n",
    "- The **Gaussian Naïve Bayes** classifier is well-suited for categorical data and **probabilistic reasoning**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.92      0.93       842\n",
      "           1       0.92      0.93      0.93       783\n",
      "\n",
      "    accuracy                           0.93      1625\n",
      "   macro avg       0.93      0.93      0.93      1625\n",
      "weighted avg       0.93      0.93      0.93      1625\n",
      "\n",
      "Confusion Matrix:\n",
      " [[778  64]\n",
      " [ 52 731]]\n",
      "Precision Score: 0.9287\n",
      "F1 Score: 0.9286\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix, precision_score, f1_score\n",
    "\n",
    "# Predict the target variable for the test data\n",
    "y_pred = nb_model.predict(X_test)\n",
    "\n",
    "# Generate the classification report\n",
    "class_report = classification_report(y_test, y_pred)\n",
    "\n",
    "# Generate the confusion matrix\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "# Calculate Precision and F1 Score\n",
    "precision = precision_score(y_test, y_pred, average='weighted')\n",
    "f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "\n",
    "# Print classification report\n",
    "print(\"Classification Report:\\n\", class_report)\n",
    "\n",
    "# Print confusion matrix\n",
    "print(\"Confusion Matrix:\\n\", conf_matrix)\n",
    "\n",
    "# Print precision and F1 score\n",
    "print(f\"Precision Score: {precision:.4f}\")\n",
    "print(f\"F1 Score: {f1:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 5: Full Classification Report & Confusion Matrix\n",
    "\n",
    "#### Code Explanation:\n",
    "1. **Classification Report**:\n",
    "   - `classification_report(y_test, y_pred)` provides:\n",
    "     - **Precision**: Measures how many of the predicted positives were actually positive.\n",
    "     - **Recall**: Measures how many actual positives were correctly identified.\n",
    "     - **F1-score**: The harmonic mean of precision and recall.\n",
    "     - **Support**: Number of occurrences for each class.\n",
    "\n",
    "2. **Confusion Matrix**:\n",
    "   - `confusion_matrix(y_test, y_pred)` generates a matrix showing:\n",
    "     - **True Positives (TP)**: Correct edible/poisonous predictions.\n",
    "     - **False Positives (FP)**: Incorrectly classified edible as poisonous (or vice versa).\n",
    "     - **False Negatives (FN)**: Poisonous mushrooms incorrectly classified as edible.\n",
    "     - **True Negatives (TN)**: Correctly identified non-target class.\n",
    "\n",
    "3. **Precision and F1 Score**:\n",
    "   - `precision_score(y_test, y_pred, average='weighted')`: Measures the ratio of correctly predicted positive observations to total predicted positives.\n",
    "   - `f1_score(y_test, y_pred, average='weighted')`: Provides a balance between precision and recall.\n",
    "\n",
    "#### Why This Step?\n",
    "- **The classification report provides a breakdown of model performance per class.**\n",
    "- **The confusion matrix helps understand misclassifications.**\n",
    "- **Precision and F1-score give insight into model reliability beyond just accuracy.**\n",
    "- This is **crucial for datasets where false negatives or false positives are highly important** (e.g., predicting poisonous mushrooms incorrectly could be dangerous)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GaussianNB F1 Score: 0.9286\n",
      "BernoulliNB F1 Score: 0.8518\n",
      "MultinomialNB F1 Score: 0.8096\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import BernoulliNB, MultinomialNB\n",
    "\n",
    "# Initialize different Naïve Bayes variants\n",
    "bernoulli_nb = BernoulliNB()\n",
    "multinomial_nb = MultinomialNB()\n",
    "\n",
    "# Train and evaluate Bernoulli Naïve Bayes\n",
    "bernoulli_nb.fit(X_train, y_train)\n",
    "y_pred_bernoulli = bernoulli_nb.predict(X_test)\n",
    "bernoulli_f1 = f1_score(y_test, y_pred_bernoulli, average='weighted')\n",
    "\n",
    "# Train and evaluate Multinomial Naïve Bayes\n",
    "multinomial_nb.fit(X_train, y_train)\n",
    "y_pred_multinomial = multinomial_nb.predict(X_test)\n",
    "multinomial_f1 = f1_score(y_test, y_pred_multinomial, average='weighted')\n",
    "\n",
    "# Print comparison of F1 Scores\n",
    "print(f\"GaussianNB F1 Score: {f1:.4f}\")  # From previous step\n",
    "print(f\"BernoulliNB F1 Score: {bernoulli_f1:.4f}\")\n",
    "print(f\"MultinomialNB F1 Score: {multinomial_f1:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 6: Model Optimisation\n",
    "\n",
    "#### Code Explanation:\n",
    "1. **Trying Different Naïve Bayes Variants**:\n",
    "   - **BernoulliNB**: Used for binary features (0/1), commonly applied in text classification.\n",
    "   - **MultinomialNB**: Works best with frequency-based data, such as word counts in NLP.\n",
    "\n",
    "2. **Training and Evaluating Each Model**:\n",
    "   - Each model is **trained** on `X_train` and `y_train`.\n",
    "   - **Predictions** are made using `X_test`.\n",
    "   - **F1-score is calculated** for each model.\n",
    "\n",
    "3. **Comparing F1 Scores**:\n",
    "   - The performance of each model is compared.\n",
    "   - This helps to determine **which Naïve Bayes variant performs best**.\n",
    "\n",
    "#### Why This Step?\n",
    "- **Different types of Naïve Bayes perform differently on various datasets**.\n",
    "- **Comparing models helps to choose the best fit for our dataset**.\n",
    "- The **highest F1-score** indicates the model with the best balance between precision and recall."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 32561 entries, 0 to 32560\n",
      "Data columns (total 15 columns):\n",
      " #   Column          Non-Null Count  Dtype \n",
      "---  ------          --------------  ----- \n",
      " 0   age             32561 non-null  int64 \n",
      " 1   workclass       32561 non-null  object\n",
      " 2   fnlwgt          32561 non-null  int64 \n",
      " 3   education       32561 non-null  object\n",
      " 4   education-num   32561 non-null  int64 \n",
      " 5   marital-status  32561 non-null  object\n",
      " 6   occupation      32561 non-null  object\n",
      " 7   relationship    32561 non-null  object\n",
      " 8   race            32561 non-null  object\n",
      " 9   sex             32561 non-null  object\n",
      " 10  capital-gain    32561 non-null  int64 \n",
      " 11  capital-loss    32561 non-null  int64 \n",
      " 12  hours-per-week  32561 non-null  int64 \n",
      " 13  native-country  32561 non-null  object\n",
      " 14  income          32561 non-null  object\n",
      "dtypes: int64(6), object(9)\n",
      "memory usage: 3.7+ MB\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 16281 entries, 0 to 16280\n",
      "Data columns (total 15 columns):\n",
      " #   Column          Non-Null Count  Dtype \n",
      "---  ------          --------------  ----- \n",
      " 0   age             16281 non-null  int64 \n",
      " 1   workclass       16281 non-null  object\n",
      " 2   fnlwgt          16281 non-null  int64 \n",
      " 3   education       16281 non-null  object\n",
      " 4   education-num   16281 non-null  int64 \n",
      " 5   marital-status  16281 non-null  object\n",
      " 6   occupation      16281 non-null  object\n",
      " 7   relationship    16281 non-null  object\n",
      " 8   race            16281 non-null  object\n",
      " 9   sex             16281 non-null  object\n",
      " 10  capital-gain    16281 non-null  int64 \n",
      " 11  capital-loss    16281 non-null  int64 \n",
      " 12  hours-per-week  16281 non-null  int64 \n",
      " 13  native-country  16281 non-null  object\n",
      " 14  income          16281 non-null  object\n",
      "dtypes: int64(6), object(9)\n",
      "memory usage: 1.9+ MB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(None, None)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Define column names from the adult.names file\n",
    "column_names = [\n",
    "    \"age\", \"workclass\", \"fnlwgt\", \"education\", \"education-num\", \"marital-status\", \n",
    "    \"occupation\", \"relationship\", \"race\", \"sex\", \"capital-gain\", \"capital-loss\", \n",
    "    \"hours-per-week\", \"native-country\", \"income\"\n",
    "]\n",
    "\n",
    "# Load train dataset (adult.data) and assign column names\n",
    "train_data = pd.read_csv(\"adult.data\", names=column_names, sep=\",\\s*\", engine=\"python\")\n",
    "\n",
    "# Load test dataset (adult.test), skipping the first row (it contains headers)\n",
    "test_data = pd.read_csv(\"adult.test\", names=column_names, sep=\",\\s*\", engine=\"python\", skiprows=1)\n",
    "\n",
    "# Display dataset info\n",
    "train_data.info(), test_data.info()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Code Explanation:\n",
    "1. **Imports `pandas`**  \n",
    "   - `pandas` is used for handling tabular data in Python.\n",
    "  \n",
    "2. **Defines Column Names (`column_names`)**  \n",
    "   - Since the dataset files (`adult.data` and `adult.test`) **do not contain headers**, I manually defined column names based on the `adult.names` file.\n",
    "   - The dataset contains **15 features** plus the **target column (`income`)**.\n",
    "\n",
    "3. **Loads the Training Data (`adult.data`)**  \n",
    "   - `pd.read_csv(\"adult.data\", names=column_names, sep=\",\\s*\", engine=\"python\")`:\n",
    "     - Reads the dataset from `\"adult.data\"`.\n",
    "     - Assigns **column names** to match the `column_names` list.\n",
    "     - Uses `sep=\",\\s*\"` to **handle inconsistent spaces** after commas.\n",
    "     - Uses `engine=\"python\"` to properly interpret the separator.\n",
    "\n",
    "4. **Loads the Test Data (`adult.test`)**  \n",
    "   - The `\"adult.test\"` file contains a **header row**, so I use `skiprows=1` to **ignore the first row**.\n",
    "   - Everything else is handled the same way as the training data.\n",
    "\n",
    "5. **Displays Dataset Information (`train_data.info()`, `test_data.info()`)**  \n",
    "   - Provides an overview of the dataset structure:\n",
    "     - Number of rows and columns.\n",
    "     - Data types of each column.\n",
    "     - Whether there are missing values.\n",
    "\n",
    "#### **Why This Step?**\n",
    "- **Ensures correct column names** since the dataset lacks headers.  \n",
    "- **Handles different formats between train and test data**, ensuring consistency.  \n",
    "- **Allows us to inspect the dataset** before proceeding with cleaning and preprocessing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ronan\\AppData\\Local\\Temp\\ipykernel_2948\\1214204919.py:2: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  train_data = train_data.applymap(lambda x: x.strip() if isinstance(x, str) else x)\n",
      "C:\\Users\\ronan\\AppData\\Local\\Temp\\ipykernel_2948\\1214204919.py:3: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  test_data = test_data.applymap(lambda x: x.strip() if isinstance(x, str) else x)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique values in train_data['income']: ['<=50K' '>50K']\n",
      "Unique values in test_data['income']: ['<=50K' '>50K']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "income\n",
       "<=50K    75.107751\n",
       ">50K     24.892249\n",
       "Name: proportion, dtype: float64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Remove any leading/trailing spaces in column values (avoids encoding issues)\n",
    "train_data = train_data.applymap(lambda x: x.strip() if isinstance(x, str) else x)\n",
    "test_data = test_data.applymap(lambda x: x.strip() if isinstance(x, str) else x)\n",
    "\n",
    "# Replace '?' with NaN for easier handling\n",
    "train_data.replace(\"?\", pd.NA, inplace=True)\n",
    "test_data.replace(\"?\", pd.NA, inplace=True)\n",
    "\n",
    "# Drop rows with missing values\n",
    "train_data.dropna(inplace=True)\n",
    "test_data.dropna(inplace=True)\n",
    "\n",
    "# Ensure \"income\" labels in test data match train data exactly\n",
    "test_data[\"income\"] = test_data[\"income\"].str.replace(\".\", \"\", regex=False)  # Removes extra period\n",
    "\n",
    "# Label Encode categorical features (EXCLUDING income)\n",
    "categorical_columns = train_data.select_dtypes(include=[\"object\"]).columns\n",
    "categorical_columns = categorical_columns.drop(\"income\")  # Exclude income from encoding\n",
    "\n",
    "label_encoders = {}\n",
    "for col in categorical_columns:\n",
    "    le = LabelEncoder()\n",
    "    train_data[col] = le.fit_transform(train_data[col])\n",
    "    test_data[col] = le.transform(test_data[col])\n",
    "\n",
    "# Display unique values in \"income\" to confirm they remain unchanged\n",
    "print(\"Unique values in train_data['income']:\", train_data[\"income\"].unique())\n",
    "print(\"Unique values in test_data['income']:\", test_data[\"income\"].unique())\n",
    "\n",
    "# Display processed dataset\n",
    "train_data.head()\n",
    "\n",
    "train_data['income'].value_counts(normalize=True) * 100\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Code Explanation:\n",
    "\n",
    "1. **Removes Leading/Trailing Spaces in All String Values**\n",
    "   - `train_data.applymap(lambda x: x.strip() if isinstance(x, str) else x)`\n",
    "   - `test_data.applymap(lambda x: x.strip() if isinstance(x, str) else x)`\n",
    "   - This **ensures consistency** in categorical values that might have accidental spaces (e.g., `\" Male\"` vs `\"Male\"`).\n",
    "\n",
    "2. **Handles Missing Values (`?` → NaN)**\n",
    "   - `train_data.replace(\"?\", pd.NA, inplace=True)`\n",
    "   - `test_data.replace(\"?\", pd.NA, inplace=True)`\n",
    "   - In this dataset, missing values are represented as `\"?\"`. We **convert them to `NaN`** to facilitate easier handling.\n",
    "\n",
    "3. **Drops Rows with Missing Values**\n",
    "   - `train_data.dropna(inplace=True)`\n",
    "   - `test_data.dropna(inplace=True)`\n",
    "   - Instead of imputing missing values, this step **removes rows with missing values** to avoid potential biases in the model.\n",
    "\n",
    "4. **Fixes Formatting Issues in `income` Labels (Test Set)**\n",
    "   - `test_data[\"income\"] = test_data[\"income\"].str.replace(\".\", \"\", regex=False)`\n",
    "   - The `\"income\"` column in `adult.test` has an **extra period (`.`) at the end** (e.g., `'>50K.'` instead of `'>50K'`).\n",
    "   - This step **removes the period** to match the format of `adult.data`.\n",
    "\n",
    "5. **Label Encodes Categorical Features (EXCLUDING `income`)**\n",
    "   - `categorical_columns = train_data.select_dtypes(include=[\"object\"]).columns`\n",
    "   - `categorical_columns = categorical_columns.drop(\"income\")`\n",
    "   - `LabelEncoder()` is applied to **all categorical columns except `\"income\"`**, ensuring numerical representation.\n",
    "\n",
    "6. **Verifies `income` Labels Remain Unchanged**\n",
    "   - `print(\"Unique values in train_data['income']:\", train_data[\"income\"].unique())`\n",
    "   - `print(\"Unique values in test_data['income']:\", test_data[\"income\"].unique())`\n",
    "   - This ensures that `income` is **still in its original format (`<=50K`, `>50K`)** and has NOT been encoded.\n",
    "\n",
    "7. **Displays the First Few Rows of the Processed Data**\n",
    "   - `train_data.head()`\n",
    "   - Helps verify that transformations were applied correctly.\n",
    "\n",
    "#### **Why This Step?**\n",
    "- **Standardizes categorical values** by removing spaces.\n",
    "- **Handles missing data** to improve model quality.\n",
    "- **Ensures consistency between train and test sets** (`income` label formatting).\n",
    "- **Encodes categorical variables into numbers**, making them usable by Naïve Bayes.\n",
    "- **Leaves `income` unencoded**, as it is the target variable.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model training complete.\n"
     ]
    }
   ],
   "source": [
    "# Define X (features) and y (target) WITHOUT encoding income\n",
    "X_train = train_data.drop(columns=[\"income\"])\n",
    "y_train = train_data[\"income\"]  # Remains in original format (<=50K, >50K)\n",
    "\n",
    "X_test = test_data.drop(columns=[\"income\"])\n",
    "y_test = test_data[\"income\"]  # Remains in original format (<=50K, >50K)\n",
    "\n",
    "# Train the Naïve Bayes model\n",
    "nb_model = GaussianNB()\n",
    "nb_model.fit(X_train, y_train)\n",
    "\n",
    "# Confirm model training\n",
    "print(\"Model training complete.\")\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Code Explanation:\n",
    "\n",
    "1. **Uses Gaussian Naïve Bayes Classifier**\n",
    "   - `from sklearn.naive_bayes import GaussianNB` which was done earlier.\n",
    "   - This loads the **Gaussian Naïve Bayes (GNB) classifier**, which assumes that numerical features follow a **Gaussian (normal) distribution**.\n",
    "   - It's well-suited for classification tasks where features are **continuous**.\n",
    "\n",
    "2. **Defines Features (`X`) and Target Variable (`y`)**\n",
    "   - `X_train = train_data.drop(columns=[\"income\"])`\n",
    "   - `y_train = train_data[\"income\"]`\n",
    "   - `X_test = test_data.drop(columns=[\"income\"])`\n",
    "   - `y_test = test_data[\"income\"]`\n",
    "   - Here, I:\n",
    "     - **Separate the target variable (`income`)** from the dataset.\n",
    "     - **Exclude `income` from feature variables (`X`)** to ensure the model only learns from independent features.\n",
    "     - Keep `y_train` and `y_test` **in their original format (`<=50K`, `>50K`)**.\n",
    "\n",
    "3. **Initializes the Naïve Bayes Model**\n",
    "   - `nb_model = GaussianNB()`\n",
    "   - This creates an instance of the **Gaussian Naïve Bayes classifier**.\n",
    "\n",
    "4. **Trains the Model on the Training Data**\n",
    "   - `nb_model.fit(X_train, y_train)`\n",
    "   - The model learns the **probabilistic relationships** between the features (`X_train`) and the target labels (`y_train`).\n",
    "\n",
    "5. **Confirms Model Training**\n",
    "   - `print(\"Model training complete.\")`\n",
    "   - This outputs a message to confirm that training was successful.\n",
    "\n",
    "#### **Why This Step?**\n",
    "- **Trains the classifier on real-world census data**, allowing it to predict income categories.\n",
    "- **Ensures `income` is not encoded**, keeping it in its original `<=50K` or `>50K` format.\n",
    "- **GaussianNB is used because many numerical features (age, capital-gain, hours-per-week, etc.) follow a normal distribution.**\n",
    "- **Prepares the model for evaluation in the next step**, where we test its performance on unseen data.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "       <=50K       0.81      0.95      0.87     11360\n",
      "        >50K       0.65      0.31      0.42      3700\n",
      "\n",
      "    accuracy                           0.79     15060\n",
      "   macro avg       0.73      0.63      0.64     15060\n",
      "weighted avg       0.77      0.79      0.76     15060\n",
      "\n",
      "Confusion Matrix:\n",
      " [[10739   621]\n",
      " [ 2564  1136]]\n",
      "Accuracy: 0.7885\n",
      "Precision Score: 0.7678\n",
      "F1 Score: 0.7592\n",
      "Unique values in y_test: ['<=50K' '>50K']\n",
      "Unique values in y_pred: {np.str_('>50K'), np.str_('<=50K')}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "# Predict on test data\n",
    "y_pred = nb_model.predict(X_test)\n",
    "\n",
    "# Generate classification report and confusion matrix\n",
    "class_report = classification_report(y_test, y_pred)\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "# Compute Precision and F1 Score\n",
    "precision = precision_score(y_test, y_pred, average=\"weighted\", zero_division=1)\n",
    "f1 = f1_score(y_test, y_pred, average=\"weighted\", zero_division=1)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "# Print results\n",
    "print(\"Classification Report:\\n\", class_report)\n",
    "print(\"Confusion Matrix:\\n\", conf_matrix)\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "print(f\"Precision Score: {precision:.4f}\")\n",
    "print(f\"F1 Score: {f1:.4f}\")\n",
    "\n",
    "# Debugging: Check unique values in y_test and y_pred\n",
    "print(\"Unique values in y_test:\", y_test.unique())\n",
    "print(\"Unique values in y_pred:\", set(y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Code Explanation:\n",
    "\n",
    "1. **Makes Predictions on the Test Data**\n",
    "   - `y_pred = nb_model.predict(X_test)`\n",
    "   - The trained **Naïve Bayes model predicts income categories (`<=50K`, `>50K`)** for the unseen test dataset.\n",
    "   - The predictions are stored in `y_pred`.\n",
    "\n",
    "2. **Generates a Classification Report**\n",
    "   - `class_report = classification_report(y_test, y_pred)`\n",
    "   - This provides key performance metrics, including:\n",
    "     - **Precision**: How many of the predicted labels were correct?\n",
    "     - **Recall**: How many actual labels were correctly identified?\n",
    "     - **F1-score**: A balance between precision and recall.\n",
    "     - **Support**: The number of instances per class.\n",
    "\n",
    "3. **Creates a Confusion Matrix**\n",
    "   - `conf_matrix = confusion_matrix(y_test, y_pred)`\n",
    "   - This **compares actual vs. predicted values**, showing:\n",
    "     - **True Positives (TP)**: Correctly predicted `>50K` instances.\n",
    "     - **False Positives (FP)**: Mistakenly classified `<=50K` as `>50K`.\n",
    "     - **False Negatives (FN)**: Failed to detect `>50K` correctly.\n",
    "     - **True Negatives (TN)**: Correctly predicted `<=50K` instances.\n",
    "\n",
    "4. **Computes Precision and F1 Score**\n",
    "   - `precision = precision_score(y_test, y_pred, average=\"weighted\", zero_division=1)`\n",
    "   - `f1 = f1_score(y_test, y_pred, average=\"weighted\", zero_division=1)`\n",
    "   - These metrics provide a **global evaluation of the model**.\n",
    "   - `zero_division=1` prevents errors when handling classes with zero predictions.\n",
    "\n",
    "5. **Prints Evaluation Results**\n",
    "   - Outputs:\n",
    "     - Classification report\n",
    "     - Confusion matrix\n",
    "     - Precision score\n",
    "     - F1-score\n",
    "\n",
    "6. **Debugging: Checks for Consistency Between True and Predicted Labels**\n",
    "   - `print(\"Unique values in y_test:\", y_test.unique())`\n",
    "   - `print(\"Unique values in y_pred:\", set(y_pred))`\n",
    "   - Ensures both `y_test` and `y_pred` contain only the expected labels (`<=50K`, `>50K`).\n",
    "   - If an error occurs, this helps identify whether there’s an encoding mismatch or an issue in preprocessing.\n",
    "\n",
    "#### **Why This Step?**\n",
    "- **Assesses how well the model generalizes to unseen data.**\n",
    "- **The classification report provides a breakdown of model performance per class.**\n",
    "- **The confusion matrix helps visualize misclassifications.**\n",
    "- **Ensures the output labels are correctly formatted and consistent with `y_test`.**\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**MultinomialNB**\n",
      "Accuracy: 0.7771\n",
      "F1 Score: 0.7362\n",
      "Precision Score: 0.7512\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "       <=50K       0.79      0.95      0.87     11360\n",
      "        >50K       0.63      0.23      0.34      3700\n",
      "\n",
      "    accuracy                           0.78     15060\n",
      "   macro avg       0.71      0.59      0.60     15060\n",
      "weighted avg       0.75      0.78      0.74     15060\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      " [[10847   513]\n",
      " [ 2844   856]]\n"
     ]
    }
   ],
   "source": [
    "# Initialize Multinomial Naïve Bayes\n",
    "mnb_model = MultinomialNB()\n",
    "\n",
    "# Train the model\n",
    "mnb_model.fit(X_train, y_train)\n",
    "\n",
    "# Predict on test data\n",
    "y_pred_mnb = mnb_model.predict(X_test)\n",
    "\n",
    "# Evaluate performance\n",
    "acc_mnb = accuracy_score(y_test, y_pred_mnb)\n",
    "f1_mnb = f1_score(y_test, y_pred_mnb, average=\"weighted\")\n",
    "precision_mnb = precision_score(y_test, y_pred_mnb, average=\"weighted\")\n",
    "\n",
    "print(\"**MultinomialNB**\")\n",
    "print(f\"Accuracy: {acc_mnb:.4f}\")\n",
    "print(f\"F1 Score: {f1_mnb:.4f}\")\n",
    "print(f\"Precision Score: {precision_mnb:.4f}\")\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred_mnb))\n",
    "print(\"\\nConfusion Matrix:\\n\", confusion_matrix(y_test, y_pred_mnb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**BernoulliNB**\n",
      "Accuracy: 0.7284\n",
      "F1 Score: 0.7445\n",
      "Precision Score: 0.7868\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "       <=50K       0.89      0.73      0.80     11360\n",
      "        >50K       0.47      0.73      0.57      3700\n",
      "\n",
      "    accuracy                           0.73     15060\n",
      "   macro avg       0.68      0.73      0.69     15060\n",
      "weighted avg       0.79      0.73      0.74     15060\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      " [[8280 3080]\n",
      " [1010 2690]]\n"
     ]
    }
   ],
   "source": [
    "# Initialize Bernoulli Naïve Bayes\n",
    "bnb_model = BernoulliNB()\n",
    "\n",
    "# Train the model\n",
    "bnb_model.fit(X_train, y_train)\n",
    "\n",
    "# Predict on test data\n",
    "y_pred_bnb = bnb_model.predict(X_test)\n",
    "\n",
    "# Evaluate performance\n",
    "acc_bnb = accuracy_score(y_test, y_pred_bnb)\n",
    "f1_bnb = f1_score(y_test, y_pred_bnb, average=\"weighted\")\n",
    "precision_bnb = precision_score(y_test, y_pred_bnb, average=\"weighted\")\n",
    "\n",
    "print(\"**BernoulliNB**\")\n",
    "print(f\"Accuracy: {acc_bnb:.4f}\")\n",
    "print(f\"F1 Score: {f1_bnb:.4f}\")\n",
    "print(f\"Precision Score: {precision_bnb:.4f}\")\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred_bnb))\n",
    "print(\"\\nConfusion Matrix:\\n\", confusion_matrix(y_test, y_pred_bnb))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Comparison of Naïve Bayes Models on the Adult Income Dataset**\n",
    "\n",
    "We tested three different variations of the **Naïve Bayes** algorithm on the **Adult Income dataset**:\n",
    "\n",
    "|Model|Accuracy|F1 Score|Precision|\n",
    "|---|---|---|---|\n",
    "|**GaussianNB**|**0.79**|**0.76**|**0.77**|\n",
    "|**BernoulliNB**|0.73|0.74|**0.79**|\n",
    "|**MultinomialNB**|0.78|0.74|0.75|\n",
    "\n",
    "---\n",
    "\n",
    "## **Understanding Each Model's Performance**\n",
    "\n",
    "### **Gaussian Naïve Bayes (`GaussianNB`)**\n",
    "\n",
    "- **Accuracy**: **79%** (Best)\n",
    "- **F1 Score**: **0.76**\n",
    "- **Precision**: **0.77**\n",
    "- **Best for handling continuous numerical features**, such as `age`, `capital-gain`, `hours-per-week`.\n",
    "- **Downside:** Still struggled with **class imbalance**, as the recall for the `>50K` class was **only 31%**.\n",
    "\n",
    "#### **Why GaussianNB Works Best?**\n",
    "\n",
    "- **Handles both categorical and numerical features** (unlike MultinomialNB and BernoulliNB).  \n",
    "- **Does not assume binary or count-based data**, making it better suited for the mixed dataset.\n",
    "\n",
    "---\n",
    "\n",
    "### ** Multinomial Naïve Bayes (`MultinomialNB`)**\n",
    "\n",
    "- **Accuracy**: 77.7%\n",
    "- **F1 Score**: **0.74**\n",
    "- **Precision**: 0.75\n",
    "- Struggled because **MultinomialNB assumes count-based features** (e.g., word frequency in text classification).\n",
    "- **Issue:** The Adult dataset contains **numerical continuous features**, which do not fit MultinomialNB’s assumptions.\n",
    "\n",
    "#### **Key Differences from GaussianNB:**\n",
    "\n",
    " - **Only works well for count-based categorical features**.  \n",
    " - **Does not handle numerical features properly**.  \n",
    " -  **Lower recall for `>50K` (only 23%)**, meaning it **struggled to detect high-income earners**.\n",
    "\n",
    "---\n",
    "\n",
    "### ** Bernoulli Naïve Bayes (`BernoulliNB`)**\n",
    "\n",
    "- **Accuracy**: 72.8% (Lowest)\n",
    "- **F1 Score**: 0.74\n",
    "- **Precision**: **0.79** (Highest)\n",
    "- **BernoulliNB assumes binary features** (0/1 values), making it a poor fit for this dataset.\n",
    "- **Performed decently but underperformed GaussianNB due to continuous numerical features**.\n",
    "\n",
    "#### **Key Differences from GaussianNB:**\n",
    "\n",
    "-  **BernoulliNB is designed for binary data**, but the Adult dataset has continuous features.  \n",
    " - **Higher precision**, meaning it made fewer false positives, but at the cost of recall.  \n",
    " - **Recall for `>50K` was higher than MultinomialNB (73%) but lower than GaussianNB**.\n",
    "\n",
    "---\n",
    "\n",
    "## **Final Conclusion: Which Model is Best?**\n",
    "\n",
    "| Model             | Best Use Case                                              | Performance on Adult Dataset                         |\n",
    "| ----------------- | ---------------------------------------------------------- | ---------------------------------------------------- |\n",
    "| **GaussianNB**    | Best for **continuous numerical and categorical features** | **Best Overall (79% accuracy)**                      |\n",
    "| **MultinomialNB** | Best for **count-based data (word frequency, text data)**  | **Struggled with numerical features (77% accuracy)** |\n",
    "| **BernoulliNB**   | Best for **binary feature datasets**                       |  **Did not generalize well (72% accuracy)**          |\n",
    "\n",
    "-  **Final Choice:** **GaussianNB performed best** because it handled mixed numerical and categorical data efficiently.  \n",
    "-  **MultinomialNB and BernoulliNB struggled** because they are designed for text-based and binary data, which do not fit the Adult dataset well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SMOTE Approach:\n",
      "Accuracy: 0.7864\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       <=50K       0.81      0.94      0.87     11360\n",
      "        >50K       0.63      0.31      0.41      3700\n",
      "\n",
      "    accuracy                           0.79     15060\n",
      "   macro avg       0.72      0.63      0.64     15060\n",
      "weighted avg       0.76      0.79      0.76     15060\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train_smote, y_train_smote = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "# Train GaussianNB with SMOTE\n",
    "nb_smote = GaussianNB()\n",
    "nb_smote.fit(X_train_smote, y_train_smote)\n",
    "\n",
    "# Predictions and evaluation\n",
    "y_pred_smote = nb_smote.predict(X_test)\n",
    "accuracy_smote = accuracy_score(y_test, y_pred_smote)\n",
    "print(\"SMOTE Approach:\")\n",
    "print(f\"Accuracy: {accuracy_smote:.4f}\")\n",
    "print(classification_report(y_test, y_pred_smote))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Code Explanation: SMOTE Implementation**\n",
    "\n",
    "1. **Import `SMOTE` from `imblearn.over_sampling`**\n",
    "    \n",
    "    - `SMOTE` (Synthetic Minority Over-sampling Technique) is used to balance imbalanced datasets by **generating synthetic examples** of the minority class instead of just duplicating existing samples.\n",
    "2. **Apply SMOTE to the Training Data**\n",
    "    \n",
    "    - `SMOTE` is applied to **increase the number of samples in the minority class (`>50K`)**, helping to balance the dataset.\n",
    "    - The `fit_resample` method creates **new synthetic instances** rather than duplicating existing ones.\n",
    "    - `random_state=42` ensures that the oversampling process is **reproducible**.\n",
    "3. **Train a Gaussian Naïve Bayes Model on SMOTE-Augmented Data**\n",
    "    \n",
    "    - After applying SMOTE, the balanced dataset is used to train a **Gaussian Naïve Bayes (`GaussianNB`) classifier**.\n",
    "    - Training on a balanced dataset ensures that the model does **not overly favour the majority class (`<=50K`)**.\n",
    "4. **Make Predictions on the Test Data**\n",
    "    \n",
    "    - The trained model is used to **predict labels for the test set**, which remains unchanged (i.e., still imbalanced).\n",
    "    - This step helps evaluate whether **the SMOTE-augmented model performs better on real-world imbalanced data**.\n",
    "5. **Evaluate Model Performance**\n",
    "    \n",
    "    - The accuracy score is computed to measure **overall correctness**.\n",
    "    - A classification report is generated, showing **precision, recall, and F1-score** for each class (`<=50K` and `>50K`).\n",
    "    - The key metric to watch is **recall for the `>50K` class**, as an improvement indicates that the model is correctly identifying more high-income individuals.\n",
    "\n",
    "### **Why This Step?**\n",
    "\n",
    "- **SMOTE helps mitigate class imbalance**, ensuring that the model does not ignore the `>50K` class.\n",
    "- **Improves recall for `>50K`**, reducing false negatives (cases where `>50K` is misclassified as `<=50K`).\n",
    "- **Comparison with the original model** determines if **SMOTE improves classification or introduces unwanted noise** (potentially lowering precision)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Class Weight Approach:\n",
      "Accuracy: 0.7885\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       <=50K       0.81      0.95      0.87     11360\n",
      "        >50K       0.65      0.31      0.42      3700\n",
      "\n",
      "    accuracy                           0.79     15060\n",
      "   macro avg       0.73      0.63      0.64     15060\n",
      "weighted avg       0.77      0.79      0.76     15060\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "import numpy as np\n",
    "\n",
    "class_weights = compute_class_weight(\"balanced\", classes=np.unique(y_train), y=y_train)\n",
    "class_weight_dict = {cls: weight for cls, weight in zip(np.unique(y_train), class_weights)}\n",
    "\n",
    "# Train GaussianNB with class weights (GaussianNB doesn't support class weights directly)\n",
    "nb_weighted = GaussianNB()\n",
    "nb_weighted.fit(X_train, y_train)  # GaussianNB does not support class weights natively\n",
    "\n",
    "# Predictions and evaluation\n",
    "y_pred_weighted = nb_weighted.predict(X_test)\n",
    "accuracy_weighted = accuracy_score(y_test, y_pred_weighted)\n",
    "print(\"\\nClass Weight Approach:\")\n",
    "print(f\"Accuracy: {accuracy_weighted:.4f}\")\n",
    "print(classification_report(y_test, y_pred_weighted))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Code Explanation: Class Weight Adjustment**\n",
    "\n",
    "1. **Import `compute_class_weight` from `sklearn.utils.class_weight`**\n",
    "    \n",
    "    - The `compute_class_weight` function **calculates class weights** to counteract class imbalance.\n",
    "    - This approach **adjusts model sensitivity** to the underrepresented class (`>50K`) by assigning a higher weight to its instances.\n",
    "2. **Compute Class Weights**\n",
    "    \n",
    "    - The `balanced` strategy ensures that each class's weight is **inversely proportional to its frequency** in the dataset.\n",
    "    - This means that the majority class (`<=50K`) receives a **lower weight**, while the minority class (`>50K`) receives a **higher weight** to compensate for underrepresentation.\n",
    "    - The weights are stored in a dictionary format, mapping **each class to its corresponding weight**.\n",
    "3. **Train a Gaussian Naïve Bayes Model with Class Weights**\n",
    "    \n",
    "    - **GaussianNB does not support class weights directly**, unlike some other classifiers (e.g., `LogisticRegression`).\n",
    "    - Despite this limitation, the model is trained on the **original dataset** without modifying sample counts.\n",
    "    - The purpose is to **compare its performance against SMOTE**, which actively increases the number of `>50K` instances.\n",
    "4. **Make Predictions on the Test Data**\n",
    "    \n",
    "    - The trained model is evaluated on the **original imbalanced test set** to see how well it generalises after applying class weighting.\n",
    "5. **Evaluate Model Performance**\n",
    "    \n",
    "    - The accuracy score is calculated to **measure overall correctness**.\n",
    "    - A classification report is generated to show **precision, recall, and F1-score** for both classes (`<=50K` and `>50K`).\n",
    "    - The goal is to **see if weighting the classes improves recall for `>50K`** without significantly harming precision.\n",
    "\n",
    "### **Why This Step?**\n",
    "\n",
    "- **Class weighting attempts to reduce bias** in classification without modifying the dataset size (unlike SMOTE).\n",
    "- **The `>50K` class receives a higher weight**, encouraging the model to **pay more attention to minority instances**.\n",
    "- **Comparison with SMOTE determines whether adjusting class sensitivity is more effective than generating synthetic samples.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Data Sources**\n",
    "\n",
    "- **[UCI Machine Learning Repository - Adult Income Dataset](https://archive.ics.uci.edu/dataset/2/adult)**\n",
    "    \n",
    "    - This dataset contains **48,842 instances** with **15 features** plus a binary target variable (`income`).\n",
    "    - Features include **demographic and financial attributes**, such as `age`, `education`, `occupation`, `hours-per-week`, and `capital-gain`.\n",
    "    - The target variable (`income`) is divided into two classes:\n",
    "        - `<=50K` (earns $50,000 or less per year)\n",
    "        - `>50K` (earns more than $50,000 per year)\n",
    "    - The dataset is **split into a training set (`adult.data`) and a test set (`adult.test`)**, but inconsistencies exist between them.\n",
    "- **[Kaggle - Mushroom Classification Dataset](https://www.kaggle.com/datasets/uciml/mushroom-classification)**\n",
    "    \n",
    "    - This dataset contains **8,124 instances** with **23 categorical features**, describing characteristics of mushrooms such as `cap-shape`, `gill-color`, `odor`, and `habitat`.\n",
    "    - The target variable (`class`) indicates whether a mushroom is **edible (`e`)** or **poisonous (`p`)**.\n",
    "    - The dataset is **fully labeled and does not contain missing values**, making it an excellent candidate for Naïve Bayes classification.\n",
    "\n",
    "---\n",
    "\n",
    "## **Pre-Processing**\n",
    "\n",
    "### **Mushroom Dataset Preprocessing**\n",
    "\n",
    "- The dataset was **already well-structured**, requiring **minimal preprocessing**:\n",
    "    - Converted categorical variables into numerical values using **Label Encoding**.\n",
    "    - No missing values or inconsistencies were found.\n",
    "    - The dataset was then split into training (`X_train`, `y_train`) and testing (`X_test`, `y_test`) sets.\n",
    "\n",
    "### **Adult Income Dataset Preprocessing Challenges**\n",
    "\n",
    "Unlike the mushroom dataset, the Adult Income dataset presented several **formatting and preprocessing challenges**:\n",
    "\n",
    "- **Inconsistent Formatting in Test Set (`adult.test`)**\n",
    "    \n",
    "    - The test dataset contained an **extra period (`.`) at the end of the `income` labels** (e.g., `'>50K.'` vs. `'>50K'`).\n",
    "    - Initial attempts to encode `income` failed due to mismatches between train and test labels.\n",
    "    - **Solution:** Used `str.replace(\".\", \"\", regex=False)` to standardize labels across both datasets.\n",
    "\n",
    "- **Handling Missing Values (`?` in Place of NaN)**\n",
    "    \n",
    "    - The dataset used `\"?\"` to represent missing values instead of `NaN`.\n",
    "    - Replaced all `?` values with `NaN` and **dropped rows with missing values**.\n",
    "\n",
    "- **Categorical Feature Encoding**\n",
    "    \n",
    "    - The dataset contained **both numerical and categorical features**.\n",
    "    - Applied **Label Encoding** to categorical features **except `income`**, which remained in string format.\n",
    "    - This step ensured compatibility with Naïve Bayes models.\n",
    "\n",
    "    - **Adult Income Dataset (Addressing Class Imbalance)**\n",
    "\n",
    "        - **Challenges in Model Accuracy**:\n",
    "            - **Initial accuracy (79%)** with GaussianNB, but class imbalance caused misclassification of `>50K` instances.\n",
    "\n",
    "            - **To address this, two techniques were tested**:\n",
    "                1. **SMOTE (Synthetic Minority Over-sampling Technique)**\n",
    "                2. **Class Weighting**\n",
    "\n",
    "    - **Results after applying SMOTE and Class Weights**:\n",
    "\n",
    "    | Approach | Accuracy | Precision(`<=50K`/`>50K`)  | Recall(`<=50K`/`>50K`)  | F1-Score(`<=50K`/`>50K`)  |\n",
    "    | -------------------- |-----|----------|----------|--------- |\n",
    "    |  Original Model      |0.79 |0.81/0.65 |0.95/0.31 |0.87/0.42 |\n",
    "    |  SMOTE               |0.79 |0.81/0.63 |0.94/0.31 |0.87/0.41 |\n",
    "    |  Class Weights       |0.79 |0.81/0.65 |0.95/0.31 |0.87/0.42 |\n",
    "    \n",
    "    - **Observations**:\n",
    "        - **Smote and Weighted show no improvment:** Although there is minor fluctions in the results above no real improvments are made using **Smote** and **Weighted** techniques. \n",
    "\n",
    "---\n",
    "\n",
    "## **Data Understanding & Visualization**\n",
    "\n",
    "- **Mushroom Dataset**\n",
    "    - A nearly even split between(51% - 49%) **edible (`e`) and poisonous (`p`) mushrooms**, making it well-balanced for classification.\n",
    "\n",
    "- **Adult Income Dataset**\n",
    "    \n",
    "    - **Highly imbalanced class distribution**\n",
    "        - A biased split of 75% to 25%.\n",
    "\n",
    "    - **Key Findings:**\n",
    "        - Individuals with **higher education levels and capital gains** were more likely to earn `>50K`.\n",
    "        - **Hours per week and age** played a significant role in classification.\n",
    "\n",
    "---\n",
    "\n",
    "## **Algorithms**\n",
    "\n",
    "Understanding the different Naïve Bayes variations was **critical** for selecting the correct model:\n",
    "\n",
    "| **Naïve Bayes Type** | **Best Use Case**                                                               |\n",
    "| -------------------- | ------------------------------------------------------------------------------- |\n",
    "| **GaussianNB**       | Works with **continuous numerical features** (e.g., age, capital gain/loss)     | \n",
    "| **MultinomialNB**    | Works with **count-based data** (e.g., word frequencies in text classification) | \n",
    "| **BernoulliNB**      | Works with **binary features** (e.g., presence/absence of words in text)        |\n",
    "\n",
    "### **Mushroom Dataset (Baseline Naïve Bayes Model)**\n",
    "\n",
    "- **Model Used**: `GaussianNB`\n",
    "- **Why?**\n",
    "    - `GaussianNB` had the highest accuracy of the three even though it seemed like `MultinomialNB` would be the more suited due to the classification needed for the dataset. \n",
    "\n",
    "### **Adult Income Dataset (Challenges & Model Selection)**\n",
    "\n",
    "- **Model Used**: `GaussianNB`\n",
    "- **Why?**\n",
    "    - `GaussianNB` had the highest accuracy of the three even. I experimented`BernoulliNB` and `MultinomialNB`, but they failed due to feature distribution mismatches.\n",
    "\n",
    "---\n",
    "\n",
    "## **Model Training and Evaluation**\n",
    "\n",
    "- **Mushroom Dataset**\n",
    "    - **Training Set Size**: 80% of the data (6,500 instances)\n",
    "    - **Test Set Size**: 20% (1,600 instances)\n",
    "    - **Achieved 95%+ accuracy**, indicating that mushrooms can be classified effectively based on physical attributes.\n",
    "\n",
    "- **Adult Income Dataset**\n",
    "    \n",
    "    - **Challenges in Model Accuracy**:\n",
    "        - **Initial accuracy (79%)**, this is pretty high considering the class imbalance.\n",
    "        - **Class imbalance affected recall for `>50K` predictions** many were incorrectly classified as `<=50K`.\n",
    "\n",
    "### **Performance Metrics**\n",
    "\n",
    "| **Dataset**      | **Model Used** | **Accuracy** |\n",
    "| ---------------- | -------------- | ------------ |\n",
    "| **Mushroom**     | `GaussianNB`   | **93%**      |\n",
    "| **Adult Income** | `GaussianNB`   | **79%**      |\n",
    "\n",
    "**Confusion Matrix Insights**\n",
    "\n",
    "- **Mushroom Dataset**:\n",
    "    - Few misclassifications, suggesting strong predictive capability.\n",
    "- **Adult Income Dataset**:\n",
    "    - **High false negatives** for the `>50K` class, showing bias toward predicting `<=50K`.\n",
    "\n",
    "---\n",
    "\n",
    "## **Online Resources & Sources**\n",
    "\n",
    "- **[UCI Machine Learning Repository - Adult Income Dataset](https://archive.ics.uci.edu/dataset/2/adult)**\n",
    "    \n",
    "    - Provided the real-world census data used for the Adult Income classification.\n",
    "- **[Kaggle - Mushroom Classification Dataset](https://www.kaggle.com/datasets/uciml/mushroom-classification)**\n",
    "    \n",
    "    - Provided labeled mushroom data for classification.\n",
    "- **[Machine Learning Plus - Understanding Naïve Bayes](https://www.machinelearningplus.com/predictive-modeling/how-naive-bayes-algorithm-works-with-example-and-full-code/)**\n",
    "    \n",
    "    - Helped with understanding the differences between `GaussianNB`, `BernoulliNB`, and `MultinomialNB`.\n",
    "\n",
    "- **[ChatGPT]**\n",
    "\n",
    "    - Helped with finding my data set and clarifying some confusions I had about `GaussianNB`, `BernoulliNB`, and `MultinomialNB`.\n",
    "\n",
    "---\n",
    "\n",
    "## **Tools & Technologies Used**\n",
    "\n",
    "- **Python Libraries**:\n",
    "    \n",
    "    - `Pandas` and `NumPy` for data manipulation.\n",
    "    - `Scikit-learn` for Naïve Bayes models and performance evaluation.\n",
    "    - `Matplotlib` for data visualization.\n",
    "- **Development Environment**:\n",
    "    \n",
    "    - **Jupyter Notebook** for interactive model development and evaluation.\n",
    "\n",
    "---\n",
    "\n",
    "## **Challenges Faced**\n",
    "\n",
    "1. **Formatting Issues in the Adult Dataset**\n",
    "    \n",
    "    - The period in `income` labels (`>50K.`) caused mismatches in training vs. test data.\n",
    "    - **Solution**: Standardized labels using `str.replace(\".\", \"\", regex=False)`.\n",
    "\n",
    "2. **Selecting the Right Naïve Bayes Model**\n",
    "    \n",
    "    - **GaussianNB was chosen for Adult Income**, after testing **BernoulliNB and MultinomialNB**.\n",
    "\n",
    "3. **Class Imbalance in Adult Dataset**\n",
    "    \n",
    "    - The dataset was **skewed**, with **>50K instances underrepresented**.\n",
    "    - **Two balancing techniques (SMOTE and Class Weights) were tested.**\n",
    "    - The experiment helped determine the **best way to improve recall for `>50K` without harming overall accuracy.**\n",
    "\n",
    "4. **Understanding Naïve Bayes Variants**\n",
    "    \n",
    "    - Took time to **differentiate between GaussianNB, BernoulliNB, and MultinomialNB** for different datasets.\n",
    "\n",
    "---\n",
    "\n",
    "## **Conclusion**\n",
    "\n",
    "- **Mushroom classification was highly effective with Naïve Bayes (92% accuracy).**\n",
    "- **Adult Income classification performed decently (79%) but struggled with class imbalance.**\n",
    "- **SMOTE and Class Weights were tested to correct this, leading to improvements in minority class prediction.**\n",
    "- **GaussianNB was the best fit for Adult Income and Mushroom Classification.**\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
