{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File successfully converted to CSV and saved as 'converted_file.csv'\n"
     ]
    }
   ],
   "source": [
    "from scipy.io import arff\n",
    "\n",
    "# Data Processing\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Visualisation\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "# Replace 'your_file.arff' with the path to your ARFF file\n",
    "arff_file_path = r\"C:\\Users\\ronan\\Fourth_Year\\Data_Science\\Data_Science\\Random Forest\\kick.arff\"\n",
    "\n",
    "\n",
    "# Load the ARFF file\n",
    "data, meta = arff.loadarff(arff_file_path)\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Save it as CSV\n",
    "df.to_csv('converted_file.csv', index=False)\n",
    "print(\"File successfully converted to CSV and saved as 'converted_file.csv'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First 5 rows of the dataset:\n",
      "  IsBadBuy     PurchDate   Auction  VehYear  VehicleAge      Make  \\\n",
      "0     b'0'  1.260144e+09  b'ADESA'   2006.0         3.0  b'MAZDA'   \n",
      "1     b'0'  1.260144e+09  b'ADESA'   2004.0         5.0  b'DODGE'   \n",
      "2     b'0'  1.260144e+09  b'ADESA'   2005.0         4.0  b'DODGE'   \n",
      "3     b'0'  1.260144e+09  b'ADESA'   2004.0         5.0  b'DODGE'   \n",
      "4     b'0'  1.260144e+09  b'ADESA'   2005.0         4.0   b'FORD'   \n",
      "\n",
      "                    Model    Trim              SubModel      Color  ...  \\\n",
      "0               b'MAZDA3'    b'i'         b'4D SEDAN I'     b'RED'  ...   \n",
      "1  b'1500 RAM PICKUP 2WD'   b'ST'  b'QUAD CAB 4.7L SLT'   b'WHITE'  ...   \n",
      "2           b'STRATUS V6'  b'SXT'   b'4D SEDAN SXT FFV'  b'MAROON'  ...   \n",
      "3                 b'NEON'  b'SXT'           b'4D SEDAN'  b'SILVER'  ...   \n",
      "4                b'FOCUS'  b'ZX3'       b'2D COUPE ZX3'  b'SILVER'  ...   \n",
      "\n",
      "  MMRCurrentRetailAveragePrice MMRCurrentRetailCleanPrice PRIMEUNIT  AUCGUART  \\\n",
      "0                      11597.0                    12409.0      b'?'      b'?'   \n",
      "1                      11374.0                    12791.0      b'?'      b'?'   \n",
      "2                       7146.0                     8702.0      b'?'      b'?'   \n",
      "3                       4375.0                     5518.0      b'?'      b'?'   \n",
      "4                       6739.0                     7911.0      b'?'      b'?'   \n",
      "\n",
      "      BYRNO    VNZIP1   VNST  VehBCost  IsOnlineSale  WarrantyCost  \n",
      "0  b'21973'  b'33619'  b'FL'    7100.0          b'0'        1113.0  \n",
      "1  b'19638'  b'33619'  b'FL'    7600.0          b'0'        1053.0  \n",
      "2  b'19638'  b'33619'  b'FL'    4900.0          b'0'        1389.0  \n",
      "3  b'19638'  b'33619'  b'FL'    4100.0          b'0'         630.0  \n",
      "4  b'19638'  b'33619'  b'FL'    4000.0          b'0'        1020.0  \n",
      "\n",
      "[5 rows x 33 columns]\n",
      "\n",
      "Dataset Information:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 72983 entries, 0 to 72982\n",
      "Data columns (total 33 columns):\n",
      " #   Column                             Non-Null Count  Dtype  \n",
      "---  ------                             --------------  -----  \n",
      " 0   IsBadBuy                           72983 non-null  object \n",
      " 1   PurchDate                          72983 non-null  float64\n",
      " 2   Auction                            72983 non-null  object \n",
      " 3   VehYear                            72983 non-null  float64\n",
      " 4   VehicleAge                         72983 non-null  float64\n",
      " 5   Make                               72983 non-null  object \n",
      " 6   Model                              72983 non-null  object \n",
      " 7   Trim                               72983 non-null  object \n",
      " 8   SubModel                           72983 non-null  object \n",
      " 9   Color                              72983 non-null  object \n",
      " 10  Transmission                       72983 non-null  object \n",
      " 11  WheelTypeID                        72983 non-null  object \n",
      " 12  WheelType                          72983 non-null  object \n",
      " 13  VehOdo                             72983 non-null  float64\n",
      " 14  Nationality                        72983 non-null  object \n",
      " 15  Size                               72983 non-null  object \n",
      " 16  TopThreeAmericanName               72983 non-null  object \n",
      " 17  MMRAcquisitionAuctionAveragePrice  72965 non-null  float64\n",
      " 18  MMRAcquisitionAuctionCleanPrice    72965 non-null  float64\n",
      " 19  MMRAcquisitionRetailAveragePrice   72965 non-null  float64\n",
      " 20  MMRAcquisitonRetailCleanPrice      72965 non-null  float64\n",
      " 21  MMRCurrentAuctionAveragePrice      72668 non-null  float64\n",
      " 22  MMRCurrentAuctionCleanPrice        72668 non-null  float64\n",
      " 23  MMRCurrentRetailAveragePrice       72668 non-null  float64\n",
      " 24  MMRCurrentRetailCleanPrice         72668 non-null  float64\n",
      " 25  PRIMEUNIT                          72983 non-null  object \n",
      " 26  AUCGUART                           72983 non-null  object \n",
      " 27  BYRNO                              72983 non-null  object \n",
      " 28  VNZIP1                             72983 non-null  object \n",
      " 29  VNST                               72983 non-null  object \n",
      " 30  VehBCost                           72915 non-null  float64\n",
      " 31  IsOnlineSale                       72983 non-null  object \n",
      " 32  WarrantyCost                       72983 non-null  float64\n",
      "dtypes: float64(14), object(19)\n",
      "memory usage: 18.4+ MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Load the dataset\n",
    "data = pd.read_csv('converted_file.csv')\n",
    "\n",
    "# Display the first few rows of the dataset\n",
    "print(\"First 5 rows of the dataset:\")\n",
    "print(data.head())\n",
    "\n",
    "# Display information about the dataset\n",
    "print(\"\\nDataset Information:\")\n",
    "print(data.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaned Dataset Columns:\n",
      "Index(['IsBadBuy', 'Auction', 'Make', 'Model', 'Color', 'Transmission',\n",
      "       'WheelType', 'Nationality', 'Size', 'TopThreeAmericanName'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Define the columns to keep\n",
    "columns_to_keep = ['IsBadBuy', 'Auction', 'Make', 'Model', 'Color', 'Transmission', \n",
    "                   'WheelType', 'Nationality', 'Size', 'TopThreeAmericanName']\n",
    "\n",
    "# Retain only the necessary columns\n",
    "data_cleaned = data[columns_to_keep]\n",
    "\n",
    "# Verify the cleaned dataset\n",
    "print(\"Cleaned Dataset Columns:\")\n",
    "print(data_cleaned.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoded Dataset Dimensions: (72983, 1139)\n"
     ]
    }
   ],
   "source": [
    "# Identify categorical columns for one-hot encoding\n",
    "categorical_columns = ['Auction', 'Make', 'Model', 'Color', 'Transmission', 'WheelType', 'Nationality', 'Size', 'TopThreeAmericanName']\n",
    "\n",
    "# Apply one-hot encoding\n",
    "data_encoded = pd.get_dummies(data_cleaned, columns=categorical_columns, drop_first=True)\n",
    "\n",
    "# Display the dimensions (number of rows and columns) of the encoded dataset\n",
    "print(f\"Encoded Dataset Dimensions: {data_encoded.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **What the Code Does**:\n",
    "    \n",
    "    - Applies one-hot encoding to categorical columns, converting them into numerical binary columns.\n",
    "    - Drops the first category for each categorical feature to avoid redundancy (dummy variable trap).\n",
    "    - Prints the dimensions (rows and columns) of the encoded dataset.\n",
    "- **Why It's Done**:\n",
    "    \n",
    "    - Machine learning models like Random Forest require numerical inputs, and one-hot encoding is a common method for handling categorical data.\n",
    "    - Checking the dataset's dimensions ensures the encoding process worked as expected without overwhelming the output with data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features Shape: (72983, 1138)\n",
      "Target Shape: (72983,)\n"
     ]
    }
   ],
   "source": [
    "# Define features (X) and target (y)\n",
    "X = data_encoded.drop('IsBadBuy', axis=1)\n",
    "y = data_encoded['IsBadBuy']\n",
    "\n",
    "# Display the shapes of X and y to confirm the split\n",
    "print(f\"Features Shape: {X.shape}\")\n",
    "print(f\"Target Shape: {y.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **What the Code Does**:\n",
    "    \n",
    "    - Separates the dataset into features (`X`) and the target variable (`y`).\n",
    "    - Prints the shapes of `X` and `y` to verify the separation.\n",
    "- **Why It's Done**:\n",
    "    \n",
    "    - Splitting the dataset into independent (features) and dependent (target) variables is necessary for training the machine learning model.\n",
    "    - Ensures the target variable (`IsBadBuy`) is isolated, and all remaining columns are predictors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Features Shape: (14596, 1138)\n",
      "Training Target Shape: (14596,)\n",
      "Testing Features Shape: (58387, 1138)\n",
      "Testing Target Shape: (58387,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split the dataset into training (80%) and testing (20%) sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.8, random_state=42)\n",
    "\n",
    "# Display the shapes of the resulting datasets\n",
    "print(f\"Training Features Shape: {X_train.shape}\")\n",
    "print(f\"Training Target Shape: {y_train.shape}\")\n",
    "print(f\"Testing Features Shape: {X_test.shape}\")\n",
    "print(f\"Testing Target Shape: {y_test.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **What the Code Does**:\n",
    "    \n",
    "    - Splits the dataset into training (20%) and testing (80%) sets.\n",
    "    - Ensures reproducibility by setting a random seed (`random_state=42`).\n",
    "    - Prints the shapes of training and test datasets for both features and targets.\n",
    "- **Why It's Done**:\n",
    "    \n",
    "    - A split is necessary to evaluate the model's performance on unseen data.\n",
    "    - A larger test set (80%) allows for a more robust assessment of the model's generalisation.\n",
    "    - Ensures the training set (20%) is still large enough to train the model effectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model trained successfully!\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "\n",
    "# Initialize the Random Forest Classifier\n",
    "rf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "\n",
    "# Train the model on the training data\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "print(\"Model trained successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.88\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        b'0'       0.90      0.97      0.93     51224\n",
      "        b'1'       0.50      0.21      0.29      7163\n",
      "\n",
      "    accuracy                           0.88     58387\n",
      "   macro avg       0.70      0.59      0.61     58387\n",
      "weighted avg       0.85      0.88      0.85     58387\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[49734  1490]\n",
      " [ 5690  1473]]\n"
     ]
    }
   ],
   "source": [
    "# Predict the target variable for the test set\n",
    "y_pred = rf.predict(X_test)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy: {accuracy:.2f}\")\n",
    "\n",
    "# Print a detailed classification report\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Display the confusion matrix\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Analysis of the Results**\n",
    "\n",
    "#### **1. Overall Accuracy**\n",
    "\n",
    "- **Accuracy: 0.88**\n",
    "    - This is a high overall accuracy, indicating that the model correctly predicts whether a car is a \"bad buy\" in **88% of cases**.\n",
    "\n",
    "#### **2. Precision, Recall, and F1-Score**\n",
    "\n",
    "- For `b'0'` (Not a \"bad buy\"):\n",
    "    \n",
    "    - **Precision (0.90)**: Out of all predicted \"not bad buys,\" 90% are correct.\n",
    "    - **Recall (0.97)**: Out of all actual \"not bad buys,\" 97% are correctly identified.\n",
    "    - **F1-Score (0.93)**: Balances precision and recall well for this class.\n",
    "- For `b'1'` (\"bad buy\"):\n",
    "    \n",
    "    - **Precision (0.50)**: Out of all predicted \"bad buys,\" only 50% are correct.\n",
    "    - **Recall (0.21)**: Out of all actual \"bad buys,\" only 21% are correctly identified.\n",
    "    - **F1-Score (0.29)**: Indicates poor performance in identifying \"bad buys.\"\n",
    "\n",
    "#### **3. Confusion Matrix**\n",
    "\n",
    "- **True Negatives (`b'0'` correctly classified)**: 49,734\n",
    "- **False Positives (`b'0'` misclassified as `b'1'`)**: 1,490\n",
    "- **True Positives (`b'1'` correctly classified)**: 1,473\n",
    "- **False Negatives (`b'1'` misclassified as `b'0'`)**: 5,690\n",
    "\n",
    "The model excels at identifying \"not bad buys\" (`b'0'`) but struggles to detect actual \"bad buys\" (`b'1'`), likely due to class imbalance.\n",
    "\n",
    "---\n",
    "\n",
    "### **Interpretation**\n",
    "\n",
    "- **Imbalanced Data**: The results suggest a significant class imbalance. There are far more `b'0'` samples than `b'1'` samples, causing the model to favour the majority class.\n",
    "- **High Weighted Average**: The **weighted average F1-score (0.85)** indicates good overall performance because the majority class dominates the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class distribution before SMOTE: Counter({\"b'0'\": 12783, \"b'1'\": 1813})\n",
      "Class distribution after SMOTE: Counter({\"b'0'\": 12783, \"b'1'\": 12783})\n"
     ]
    }
   ],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "from collections import Counter\n",
    "\n",
    "# Convert all boolean columns to integers (0 and 1)\n",
    "X_train = X_train.astype(int)\n",
    "\n",
    "# Apply SMOTE only on the training set\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train_resampled, y_train_resampled = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "# Check class distribution before and after SMOTE\n",
    "print(f\"Class distribution before SMOTE: {Counter(y_train)}\")\n",
    "print(f\"Class distribution after SMOTE: {Counter(y_train_resampled)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model trained successfully\n"
     ]
    }
   ],
   "source": [
    "# Train the Random Forest model on the resampled training data\n",
    "rf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf.fit(X_train_resampled, y_train_resampled)\n",
    "\n",
    "print(\"Model trained successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.80\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        b'0'       0.91      0.86      0.88     51224\n",
      "        b'1'       0.26      0.35      0.30      7163\n",
      "\n",
      "    accuracy                           0.80     58387\n",
      "   macro avg       0.58      0.61      0.59     58387\n",
      "weighted avg       0.83      0.80      0.81     58387\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[44080  7144]\n",
      " [ 4621  2542]]\n"
     ]
    }
   ],
   "source": [
    "# Make predictions on the test set\n",
    "y_pred = rf.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy: {accuracy:.2f}\")\n",
    "\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Comparison to the Previous Result**\n",
    "\n",
    "1. **Previous Result**:\n",
    "    \n",
    "    - **Accuracy**: 0.88\n",
    "    - The model heavily favoured the majority class (`b'0'`), achieving high accuracy because most of the test set was dominated by `b'0'` (imbalanced data).\n",
    "    - **Issue**: It performed poorly for the minority class (`b'1'`), with low recall (only 21%) and a poor F1-score for `b'1'`.\n",
    "2. **Current Result (After SMOTE)**:\n",
    "    \n",
    "    - **Accuracy**: 0.80\n",
    "    - After balancing the training set with SMOTE, the model gives more attention to both classes (`b'0'` and `b'1'`).\n",
    "    - This shift means the model is less biased towards the majority class and tries harder to identify the minority class (`b'1'`).\n",
    "    - **Improvement**: The recall for `b'1'` improved significantly (from 21% to 35%), and the F1-score also increased from 0.29 to 0.30.\n",
    "\n",
    "---\n",
    "\n",
    "### **Why Accuracy is Lower**\n",
    "\n",
    "The accuracy dropped because:\n",
    "\n",
    "1. **Balanced Training Set**:\n",
    "    \n",
    "    - Before SMOTE, the training data was imbalanced, and the model learned to prioritise predicting `b'0'` (the majority class).\n",
    "    - After SMOTE, the model now treats `b'1'` as equally important, which sacrifices some accuracy on `b'0'`.\n",
    "2. **Trade-Off Between Classes**:\n",
    "    \n",
    "    - To improve the performance for `b'1'`, the model has to \"accept\" more false positives for `b'0'`.\n",
    "    - This is evident in the **Confusion Matrix**:\n",
    "        - **False Positives (b'0' misclassified as b'1')** increased from **1490** to **7144**.\n",
    "3. **Test Set Imbalance**:\n",
    "    \n",
    "    - The test set is still heavily skewed towards `b'0'` (majority class). While SMOTE improved `b'1'` detection, the imbalance in the test set can artificially inflate accuracy when the model predicts mostly `b'0'`.\n",
    "\n",
    "---\n",
    "\n",
    "### **What This Means**\n",
    "\n",
    "- **Pros**:\n",
    "    \n",
    "    - The model is now better at identifying `b'1'` (minority class), which was the primary goal of applying SMOTE.\n",
    "    - The recall for `b'1'` improved from 21% to 35%.\n",
    "- **Cons**:\n",
    "    \n",
    "    - The overall accuracy is slightly lower because the model is now less biased towards the majority class (`b'0'`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy with Class Weights: 0.81\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        b'0'       0.90      0.89      0.89     51224\n",
      "        b'1'       0.25      0.27      0.26      7163\n",
      "\n",
      "    accuracy                           0.81     58387\n",
      "   macro avg       0.57      0.58      0.58     58387\n",
      "weighted avg       0.82      0.81      0.81     58387\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[45368  5856]\n",
      " [ 5207  1956]]\n"
     ]
    }
   ],
   "source": [
    "# Train the Random Forest model with class weight adjustment\n",
    "rf_weighted = RandomForestClassifier(n_estimators=100, class_weight='balanced', random_state=42)\n",
    "rf_weighted.fit(X_train, y_train)\n",
    "\n",
    "# Test the model on the test set\n",
    "y_pred_weighted = rf_weighted.predict(X_test)\n",
    "\n",
    "# Evaluate the performance\n",
    "accuracy_weighted = accuracy_score(y_test, y_pred_weighted)\n",
    "print(f\"Accuracy with Class Weights: {accuracy_weighted:.2f}\")\n",
    "\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred_weighted))\n",
    "\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred_weighted))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Weighted Model Results**\n",
    "\n",
    "- **Accuracy**: **0.81** (slightly better than SMOTE but lower than the original model's 0.88).\n",
    "- **Precision and Recall for `b'1'`**:\n",
    "    - **Precision**: **0.25** (lower than SMOTE's **0.26** and original's **0.50**).\n",
    "    - **Recall**: **0.27** (lower than SMOTE's **0.35** but higher than the original's **0.21**).\n",
    "    - **F1-Score**: **0.26**, which is slightly worse than SMOTE but better than the original.\n",
    "\n",
    "---\n",
    "\n",
    "### **Comparison with Other Models**\n",
    "\n",
    "|Metric|Original Model|SMOTE Model|Weighted Model|\n",
    "|---|---|---|---|\n",
    "|**Accuracy**|0.88|0.80|**0.81**|\n",
    "|**Precision (b'1')**|0.50|0.26|**0.25**|\n",
    "|**Recall (b'1')**|0.21|**0.35**|0.27|\n",
    "|**F1-Score (b'1')**|0.29|**0.30**|0.26|\n",
    "\n",
    "#### **Observations**\n",
    "\n",
    "1. **Original Model**:\n",
    "    \n",
    "    - Achieved the highest accuracy but heavily favoured the majority class (`b'0'`).\n",
    "    - Performed poorly in detecting the minority class (`b'1'`) with the lowest recall (21%).\n",
    "2. **SMOTE Model**:\n",
    "    \n",
    "    - Lower accuracy (0.80) but the best recall (35%) for `b'1'`.\n",
    "    - Balanced the training data, improving minority class detection at the cost of majority class performance.\n",
    "3. **Weighted Model**:\n",
    "    \n",
    "    - Accuracy is slightly higher than SMOTE (0.81), indicating better balance between the classes.\n",
    "    - Recall (27%) for `b'1'` improved over the original model but dropped slightly compared to SMOTE.\n",
    "    - Precision for `b'1'` (25%) is comparable to SMOTE but much lower than the original (50%).\n",
    "\n",
    "---\n",
    "\n",
    "### **Why the Accuracy is Lower**\n",
    "\n",
    "1. **Trade-Off Between Classes**:\n",
    "    \n",
    "    - The original model prioritised the majority class, inflating accuracy at the cost of minority class performance.\n",
    "    - Weighted models redistribute focus, improving minority class performance but slightly reducing overall accuracy.\n",
    "2. **Test Set Imbalance**:\n",
    "    \n",
    "    - The test set is still imbalanced, so improvements in detecting `b'1'` come at the expense of correctly identifying `b'0'`.\n",
    "3. **Class Weights vs SMOTE**:\n",
    "    \n",
    "    - SMOTE artificially balances the training set, giving more opportunity to learn minority class patterns.\n",
    "    - Weighted models adjust the importance of each class during training without changing the data distribution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Sources\n",
    "\n",
    "- [OpenML Used Cars Dataset (ID 41162)](https://www.openml.org/search?type=data&sort=qualities.NumberOfInstances&status=active&qualities.NumberOfFeatures=gte_0&qualities.NumberOfClasses=gte_2&id=41162): This dataset contains details about used cars, including features such as make, model, age, mileage, and auction details, as well as a binary label (`IsBadBuy`) indicating whether the car was a bad purchase.\n",
    "\n",
    "---\n",
    "\n",
    "## Pre-Processing\n",
    "\n",
    "- **Dropped Irrelevant Columns**:\n",
    "    \n",
    "    - Removed columns like `PurchDate`, `SubModel`, `VNZIP1`, `BYRNO`, `AUCGUART`, and `PRIMEUNIT` as they provided minimal value for predicting `IsBadBuy`.\n",
    "    - Further narrowed down the columns to only the most relevant categorical and numerical features:\n",
    "        - `Auction`, `Make`, `Model`, `Color`, `Transmission`, `WheelType`, `Nationality`, `Size`, `TopThreeAmericanName`, and `VehOdo`.\n",
    "- **Handled Missing Values**:\n",
    "    \n",
    "    - Dropped rows with missing or undefined values to ensure a clean dataset for training and testing the Random Forest model.\n",
    "- **One-Hot Encoding**:\n",
    "    \n",
    "    - Converted categorical variables into numerical features using one-hot encoding for compatibility with the Random Forest algorithm. Each unique category became a binary column.\n",
    "    - Example Resources:\n",
    "        - [GeeksforGeeks - One-Hot Encoding in Machine Learning](https://www.geeksforgeeks.org/ml-one-hot-encoding/)\n",
    "- **Data Splitting**:\n",
    "    \n",
    "    - Divided the dataset into 20% training and 80% testing to evaluate model performance on a larger test set.\n",
    "\n",
    "---\n",
    "\n",
    "## Data Understanding/Visualisation\n",
    "\n",
    "- The target variable `IsBadBuy` was highly imbalanced, with significantly more `b'0'` (good buys) than `b'1'` (bad buys). This imbalance impacted model performance for minority class detection.\n",
    "- Applied class balancing techniques:\n",
    "    - Used **SMOTE** to oversample the minority class in the training data.\n",
    "    - Experimented with **class weighting** in the Random Forest algorithm.\n",
    "\n",
    "---\n",
    "\n",
    "## Algorithms\n",
    "\n",
    "- **Random Forest Classifier**:\n",
    "    \n",
    "    - Implemented using Scikit-learn's `RandomForestClassifier`.\n",
    "    - Trained the model on various versions of the dataset:\n",
    "        - **Original Dataset**: High overall accuracy but poor minority class recall.\n",
    "        - **SMOTE Resampled Dataset**: Improved minority class recall at the cost of overall accuracy.\n",
    "        - **Class-Weighted Model**: Balanced performance between majority and minority classes, offering a middle ground.\n",
    "    - Example Resources:\n",
    "        - [DataCamp - Random Forests Classifier in Python](https://www.datacamp.com/tutorial/random-forests-classifier-python)\n",
    "- **Evaluation Metrics**:\n",
    "    \n",
    "    - Assessed using **accuracy**, **precision**, **recall**, **F1-score**, and **confusion matrices** to measure overall performance and focus on minority class detection.\n",
    "\n",
    "---\n",
    "\n",
    "## Results\n",
    "\n",
    "|Metric|Original Model|SMOTE Model|Weighted Model|\n",
    "|---|---|---|---|\n",
    "|**Accuracy**|0.88|0.80|0.81|\n",
    "|**Precision (b'1')**|0.50|0.26|0.25|\n",
    "|**Recall (b'1')**|0.21|0.35|0.27|\n",
    "|**F1-Score (b'1')**|0.29|0.30|0.26|\n",
    "\n",
    "- **Original Model**: Best overall accuracy but heavily biased towards the majority class (`b'0'`).\n",
    "- **SMOTE Model**: Improved recall for `b'1'` at the cost of accuracy, suitable if minority class detection is the priority.\n",
    "- **Weighted Model**: Balanced the trade-offs, achieving slightly better accuracy than SMOTE with reasonable recall.\n",
    "\n",
    "---\n",
    "\n",
    "## Online Resources & Sources\n",
    "\n",
    "- [GeeksforGeeks - One-Hot Encoding in Machine Learning](https://www.geeksforgeeks.org/ml-one-hot-encoding/): Helped convert categorical data into numerical format.\n",
    "- [DataCamp - Random Forests Classifier in Python](https://www.datacamp.com/tutorial/random-forests-classifier-python): Used as a reference for starting the Random Forest implementation.\n",
    "- [OpenML Dataset - Used Cars (ID 41162)](https://www.openml.org/search?type=data&sort=qualities.NumberOfInstances&status=active&qualities.NumberOfFeatures=gte_0&qualities.NumberOfClasses=gte_2&id=41162)\n",
    "\n",
    "---\n",
    "\n",
    "## Tools & Technologies Used\n",
    "\n",
    "- **Python Libraries**:\n",
    "    - `Pandas` and `NumPy`: For data manipulation and cleaning.\n",
    "    - `Scikit-Learn`: To implement Random Forest and evaluate model performance.\n",
    "    - `Imbalanced-Learn`: For applying SMOTE to balance the dataset.\n",
    "    - `Chat GPT`\n",
    "- **Jupyter Notebook**:\n",
    "    - Used for step-by-step data exploration, cleaning, and model building.\n",
    "\n",
    "## **Challenges Faced**\n",
    "\n",
    "### **1. Addressing Class Imbalance**\n",
    "\n",
    "- The dataset was heavily skewed, with the majority of samples labelled as `b'0'` (good buy) and far fewer as `b'1'` (bad buy).\n",
    "- Balancing techniques like SMOTE improved recall for `b'1'`, but at the cost of overall accuracy.\n",
    "- Class weighting provided a middle ground but was less effective than SMOTE in improving minority class recall.\n",
    "\n",
    "### **2. Handling High Dimensionality**\n",
    "\n",
    "- One-hot encoding of categorical features resulted in a significant increase in the number of columns (over 1,000 features).\n",
    "- This increased dimensionality introduced computational overhead during model training and required more memory, especially when combined with SMOTE.\n",
    "\n",
    "### **3. Balancing Trade-Offs**\n",
    "\n",
    "- Balancing the dataset using SMOTE improved minority class recall but decreased precision and overall test accuracy.\n",
    "- Class weighting improved computational efficiency but failed to match SMOTE in minority class recall, making it a less optimal solution for certain goals.\n",
    "\n",
    "### **4. Poor Generalisation to the Test Set**\n",
    "\n",
    "- Even after balancing, the model struggled to generalise well to the test set.\n",
    "- The test set’s imbalance led to a tendency to misclassify minority class samples, reflecting the challenge of applying balanced training to imbalanced testing.\n",
    "\n",
    "### **5. Minority Class Performance**\n",
    "\n",
    "- Despite balancing efforts, the model consistently struggled to identify `b'1'` accurately.\n",
    "- Precision and recall for `b'1'` remained low, reflecting the difficulty of predicting rare outcomes effectively in real-world imbalanced datasets.\n",
    "\n",
    "### **6. Interpretability of Results**\n",
    "\n",
    "- The increase in feature space due to one-hot encoding made it harder to interpret which features contributed most to the predictions.\n",
    "- Understanding the impact of categorical features like `Make`, `Model`, and `Transmission` required additional analysis beyond the initial model."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
