{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Data:\n",
      "   Unnamed: 0                  drugName                     condition  \\\n",
      "0      206461                 Valsartan  Left Ventricular Dysfunction   \n",
      "1       95260                Guanfacine                          ADHD   \n",
      "2       92703                    Lybrel                 Birth Control   \n",
      "3      138000                Ortho Evra                 Birth Control   \n",
      "4       35696  Buprenorphine / naloxone             Opiate Dependence   \n",
      "\n",
      "                                              review  rating  \\\n",
      "0  \"It has no side effect, I take it in combinati...     9.0   \n",
      "1  \"My son is halfway through his fourth week of ...     8.0   \n",
      "2  \"I used to take another oral contraceptive, wh...     5.0   \n",
      "3  \"This is my first time using any form of birth...     8.0   \n",
      "4  \"Suboxone has completely turned my life around...     9.0   \n",
      "\n",
      "                date  usefulCount  \n",
      "0       May 20, 2012           27  \n",
      "1     April 27, 2010          192  \n",
      "2  December 14, 2009           17  \n",
      "3   November 3, 2015           10  \n",
      "4  November 27, 2016           37  \n",
      "\n",
      "Test Data:\n",
      "   Unnamed: 0         drugName                     condition  \\\n",
      "0      163740      Mirtazapine                    Depression   \n",
      "1      206473       Mesalamine  Crohn's Disease, Maintenance   \n",
      "2      159672          Bactrim       Urinary Tract Infection   \n",
      "3       39293         Contrave                   Weight Loss   \n",
      "4       97768  Cyclafem 1 / 35                 Birth Control   \n",
      "\n",
      "                                              review  rating  \\\n",
      "0  \"I&#039;ve tried a few antidepressants over th...    10.0   \n",
      "1  \"My son has Crohn&#039;s disease and has done ...     8.0   \n",
      "2                      \"Quick reduction of symptoms\"     9.0   \n",
      "3  \"Contrave combines drugs that were used for al...     9.0   \n",
      "4  \"I have been on this birth control for one cyc...     9.0   \n",
      "\n",
      "                 date  usefulCount  \n",
      "0   February 28, 2012           22  \n",
      "1        May 17, 2009           17  \n",
      "2  September 29, 2017            3  \n",
      "3       March 5, 2017           35  \n",
      "4    October 22, 2015            4  \n",
      "\n",
      "Training Data Info:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 161297 entries, 0 to 161296\n",
      "Data columns (total 7 columns):\n",
      " #   Column       Non-Null Count   Dtype  \n",
      "---  ------       --------------   -----  \n",
      " 0   Unnamed: 0   161297 non-null  int64  \n",
      " 1   drugName     161297 non-null  object \n",
      " 2   condition    160398 non-null  object \n",
      " 3   review       161297 non-null  object \n",
      " 4   rating       161297 non-null  float64\n",
      " 5   date         161297 non-null  object \n",
      " 6   usefulCount  161297 non-null  int64  \n",
      "dtypes: float64(1), int64(2), object(4)\n",
      "memory usage: 8.6+ MB\n",
      "None\n",
      "\n",
      "Test Data Info:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 53766 entries, 0 to 53765\n",
      "Data columns (total 7 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   Unnamed: 0   53766 non-null  int64  \n",
      " 1   drugName     53766 non-null  object \n",
      " 2   condition    53471 non-null  object \n",
      " 3   review       53766 non-null  object \n",
      " 4   rating       53766 non-null  float64\n",
      " 5   date         53766 non-null  object \n",
      " 6   usefulCount  53766 non-null  int64  \n",
      "dtypes: float64(1), int64(2), object(4)\n",
      "memory usage: 2.9+ MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Data Processing\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Visualisation\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load the training data\n",
    "train_data = pd.read_csv('drugsComTrain_raw.tsv', sep='\\t')\n",
    "\n",
    "# Load the test data\n",
    "test_data = pd.read_csv('drugsComTest_raw.tsv', sep='\\t')\n",
    "\n",
    "# Display the first few rows of each dataset\n",
    "print(\"Training Data:\")\n",
    "print(train_data.head())\n",
    "\n",
    "print(\"\\nTest Data:\")\n",
    "print(test_data.head())\n",
    "\n",
    "# Optional: Display basic info about the datasets\n",
    "print(\"\\nTraining Data Info:\")\n",
    "print(train_data.info())\n",
    "\n",
    "print(\"\\nTest Data Info:\")\n",
    "print(test_data.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Training Data**\n",
    "\n",
    "- **Total Entries**: 161,297 rows\n",
    "    \n",
    "- **Columns**:\n",
    "    \n",
    "    1. **`Unnamed: 0`**: An index-like column that likely corresponds to the original dataset's row numbers.\n",
    "    2. **`drugName`**: The name of the drug being reviewed (e.g., \"Valsartan\").\n",
    "    3. **`condition`**: The medical condition for which the drug was prescribed (e.g., \"ADHD\"). Note that some values are missing in this column.\n",
    "    4. **`review`**: A text review from the patient about the drug.\n",
    "    5. **`rating`**: A numerical score (out of 10) reflecting the patientâ€™s satisfaction with the drug.\n",
    "    6. **`date`**: The date the review was written.\n",
    "    7. **`usefulCount`**: The number of users who found the review helpful.\n",
    "- **Key Observations**:\n",
    "    \n",
    "    - The dataset has missing values in the `condition` column.\n",
    "    - `review` is textual data, suitable for sentiment analysis or text feature extraction.\n",
    "    - `rating` is the target variable for regression or classification tasks.\n",
    "\n",
    "#### **Test Data**\n",
    "\n",
    "- **Total Entries**: 53,766 rows\n",
    "- **Columns**: The same as the training data.\n",
    "- **Key Differences**:\n",
    "    - Smaller size compared to the training data.\n",
    "    - The `condition` column also has missing values here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files successfully converted to CSV!\n"
     ]
    }
   ],
   "source": [
    "# Convert training data\n",
    "train_data.to_csv('drugsComTrain_raw.csv', index=False)\n",
    "\n",
    "# Convert test data\n",
    "test_data.to_csv('drugsComTest_raw.csv', index=False)\n",
    "\n",
    "print(\"Files successfully converted to CSV!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = train_data.dropna()\n",
    "test_data = test_data.dropna()\n",
    "\n",
    "features = ['drugName', 'condition', 'usefulCount']\n",
    "target = 'rating'\n",
    "\n",
    "train_data = train_data.drop(columns=['review', 'date'])\n",
    "test_data = test_data.drop(columns=['review', 'date'])\n",
    "\n",
    "# Convert categorical variables 'drugName' and 'condition' into one-hot encoded columns.\n",
    "# drop_first=True avoids the dummy variable trap by removing the first category.\n",
    "train_data_cleaned = pd.get_dummies(train_data, columns=['drugName', 'condition'], drop_first=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Code Explanation**\n",
    "\n",
    "#### **Step 1: Drop Rows with Missing Values**\n",
    "\n",
    "The lines `train_data = train_data.dropna()` and `test_data = test_data.dropna()` remove any rows in the training and test datasets that contain missing values (`NaN`). This is necessary because missing values can disrupt the training process, as machine learning models typically require complete data for all features.\n",
    "\n",
    "#### **Step 2: Define Features and Target**\n",
    "\n",
    "The `features` variable specifies the columns to use as input features (`drugName`, `condition`, `usefulCount`), and the `target` variable defines the column to predict (`rating`). This separation ensures the model knows which data to use for predictions and what to predict.\n",
    "\n",
    "#### **Step 3: Drop Irrelevant Columns**\n",
    "\n",
    "The lines `train_data = train_data.drop(columns=['review', 'date'])` and `test_data = test_data.drop(columns=['review', 'date'])` remove the `review` and `date` columns. These columns are dropped because they are either uninformative (`date`) or incompatible with the model (`review`, as it contains text).\n",
    "\n",
    "#### **Step 4: One-Hot Encode Categorical Variables**\n",
    "\n",
    "The line `train_data_cleaned = pd.get_dummies(train_data, columns=['drugName', 'condition'], drop_first=True)` converts the categorical variables `drugName` and `condition` into one-hot encoded numerical columns. The parameter `drop_first=True` removes the first category to prevent redundancy (known as the dummy variable trap). This step is essential because machine learning models like Random Forest require numerical input and cannot process categorical text directly.\n",
    "\n",
    "---\n",
    "\n",
    "### **Purpose of the Code**\n",
    "\n",
    "This code prepares the data for training by:\n",
    "\n",
    "1. Cleaning missing values to ensure complete data.\n",
    "2. Defining the input features and target variable.\n",
    "3. Removing irrelevant or problematic columns (`review`, `date`).\n",
    "4. Converting categorical data (`drugName` and `condition`) into a format that the model can understand (one-hot encoding)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Features: (160398, 4315)\n",
      "Test Features: (53471, 3075)\n",
      "Training Target: (160398,)\n",
      "Test Target: (53471,)\n"
     ]
    }
   ],
   "source": [
    "# Select features and target for training data\n",
    "X_train = train_data_cleaned.drop('rating', axis=1)\n",
    "y_train = train_data_cleaned['rating']\n",
    "\n",
    "# Apply the same preprocessing to test data (dropping NaNs and encoding)\n",
    "test_data_cleaned = pd.get_dummies(test_data, columns=['drugName', 'condition'], drop_first=True)\n",
    "\n",
    "# Ensure test data has the same columns as training data\n",
    "X_test = test_data_cleaned[X_train.columns.intersection(test_data_cleaned.columns)]\n",
    "y_test = test_data_cleaned['rating']\n",
    "\n",
    "# Print shapes to verify alignment\n",
    "print(f\"Training Features: {X_train.shape}\")\n",
    "print(f\"Test Features: {X_test.shape}\")\n",
    "print(f\"Training Target: {y_train.shape}\")\n",
    "print(f\"Test Target: {y_test.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Code Explanation**\n",
    "\n",
    "#### **Step 1: Separate Features and Target for Training Data**\n",
    "\n",
    "The line `X_train = train_data_cleaned.drop('rating', axis=1)` selects all columns except the target column (`rating`) as the features for training. The target column (`rating`) is assigned to `y_train`.\n",
    "\n",
    "- **Outcome**:\n",
    "    - `X_train` contains the input data (independent variables) for training, with 160,398 rows (samples) and 4,315 columns (features).\n",
    "    - `y_train` contains the corresponding target values (dependent variable), with 160,398 rows (samples).\n",
    "\n",
    "---\n",
    "\n",
    "#### **Step 2: Preprocess the Test Data**\n",
    "\n",
    "The line `test_data_cleaned = pd.get_dummies(test_data, columns=['drugName', 'condition'], drop_first=True)` applies the same one-hot encoding to the test data as was applied to the training data. This step ensures the categorical variables `drugName` and `condition` are transformed into numerical columns for the test data.\n",
    "\n",
    "---\n",
    "\n",
    "#### **Step 3: Align Test Data Columns with Training Data**\n",
    "\n",
    "The line `X_test = test_data_cleaned[X_train.columns.intersection(test_data_cleaned.columns)]` ensures that the test data (`X_test`) has the same set of columns (features) as the training data (`X_train`). Any columns in the training data that are missing in the test data will not be included, and any extra columns in the test data will be excluded.\n",
    "\n",
    "The target column (`rating`) is then extracted from the test data and assigned to `y_test`.\n",
    "\n",
    "- **Outcome**:\n",
    "    - `X_test` contains 53,471 rows (samples) and 3,075 columns (features). The reduced feature count (compared to training) is due to missing categories in the test data.\n",
    "    - `y_test` contains 53,471 rows (samples) of the corresponding target values.\n",
    "\n",
    "---\n",
    "\n",
    "#### **Step 4: Print Shapes to Verify Alignment**\n",
    "\n",
    "The shapes of the training and test data are printed to ensure alignment:\n",
    "\n",
    "- `X_train.shape`: (160,398 rows, 4,315 columns) indicates the training features.\n",
    "- `y_train.shape`: (160,398 rows) indicates the training target.\n",
    "- `X_test.shape`: (53,471 rows, 3,075 columns) indicates the test features.\n",
    "- `y_test.shape`: (53,471 rows) indicates the test target.\n",
    "\n",
    "**Discrepancy**: The number of features in `X_train` (4,315) and `X_test` (3,075) differs, which might cause issues during model prediction unless handled properly (e.g., filling missing columns in the test data with zeros)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest model trained successfully!\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Initialize the Random Forest Classifier\n",
    "rf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "\n",
    "# Train the model\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "print(\"Random Forest model trained successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Code Explanation\n",
    "#### **Step 1: Initialize the Random Forest Model**\n",
    "\n",
    "The line `rf = RandomForestClassifier(n_estimators=100, random_state=42)` creates an instance of the Random Forest Classifier with the following parameters:\n",
    "\n",
    "- **`n_estimators=100`**: Specifies the number of decision trees in the forest. More trees generally improve accuracy but increase training time.\n",
    "- **`random_state=42`**: Sets a random seed to ensure reproducibility of results.\n",
    "\n",
    "---\n",
    "\n",
    "#### **Step 2: Train the Model**\n",
    "\n",
    "The line `rf.fit(X_train, y_train)` trains the Random Forest model using the **training features (`X_train`)** and **training target (`y_train`)**:\n",
    "\n",
    "- During training, the model creates 100 decision trees, each trained on a random subset of the training data.\n",
    "- Predictions from all trees are combined (e.g., majority voting for classification) to improve overall accuracy and reduce overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.28\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.30      0.31      0.30      7265\n",
      "         2.0       0.07      0.06      0.07      2324\n",
      "         3.0       0.07      0.05      0.06      2197\n",
      "         4.0       0.05      0.04      0.05      1642\n",
      "         5.0       0.08      0.06      0.07      2691\n",
      "         6.0       0.07      0.06      0.06      2102\n",
      "         7.0       0.08      0.07      0.07      3075\n",
      "         8.0       0.14      0.12      0.13      6118\n",
      "         9.0       0.21      0.20      0.21      9120\n",
      "        10.0       0.45      0.54      0.49     16937\n",
      "\n",
      "    accuracy                           0.28     53471\n",
      "   macro avg       0.15      0.15      0.15     53471\n",
      "weighted avg       0.25      0.28      0.26     53471\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[2240  442  331  242  374  269  363  669  738 1597]\n",
      " [ 532  140  163   89  152   84  146  239  279  500]\n",
      " [ 453  130  117   97  143   92  143  234  295  493]\n",
      " [ 317   86  102   70   94   75  101  159  240  398]\n",
      " [ 494  131  150  107  173  114  159  299  387  677]\n",
      " [ 321   99   81   84  130  117  141  254  322  553]\n",
      " [ 425  119  119   85  140  128  204  403  526  926]\n",
      " [ 673  203  195  135  262  222  346  727 1112 2243]\n",
      " [ 775  244  205  164  336  241  422  941 1817 3975]\n",
      " [1306  370  327  253  403  352  525 1393 2780 9228]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "\n",
    "X_test = test_data_cleaned.reindex(columns=X_train.columns, fill_value=0)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = rf.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy: {accuracy:.2f}\")\n",
    "\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Code Explanation\n",
    "#### **Step 1: Align Test Data Columns**\n",
    "\n",
    "The line `X_test = test_data_cleaned.reindex(columns=X_train.columns, fill_value=0)` ensures that the test data (`X_test`) has the same columns as the training data (`X_train`):\n",
    "\n",
    "- **Why itâ€™s needed**: After one-hot encoding, training and test datasets might have different columns due to missing categories in one dataset. This alignment fills missing columns in `X_test` with zeros, ensuring compatibility with the trained model.\n",
    "\n",
    "---\n",
    "\n",
    "#### **Step 2: Make Predictions**\n",
    "\n",
    "The line `y_pred = rf.predict(X_test)` uses the trained Random Forest model (`rf`) to predict the target values (`rating`) for the test data (`X_test`):\n",
    "\n",
    "- The model generates predictions based on the features in `X_test` and the patterns it learned from the training data.\n",
    "\n",
    "---\n",
    "\n",
    "#### **Step 3: Evaluate the Model**\n",
    "\n",
    "- **`accuracy_score(y_test, y_pred)`**: Calculates the accuracy of the model (correct predictions divided by total predictions).\n",
    "    \n",
    "    - **Outcome**: The model achieves an accuracy of **28%**, which is quite low.\n",
    "- **`classification_report(y_test, y_pred)`**: Provides precision, recall, and F1-score for each class (ratings 1.0 to 10.0):\n",
    "    \n",
    "    - **Precision**: The proportion of correct predictions for a class among all predictions for that class.\n",
    "        \n",
    "    - **Recall**: The proportion of correct predictions for a class among all true instances of that class.\n",
    "        \n",
    "    - **F1-Score**: The harmonic mean of precision and recall.\n",
    "        \n",
    "    - **Outcome**:\n",
    "        \n",
    "        - The model performs better for the majority class (rating 10.0), with higher precision and recall.\n",
    "        - Performance for minority classes (e.g., 2.0, 3.0, 4.0) is very poor, with low precision, recall, and F1-scores.\n",
    "- **`confusion_matrix(y_test, y_pred)`**: Displays a matrix where rows represent actual classes and columns represent predicted classes:\n",
    "    \n",
    "    - Diagonal values represent correct predictions.\n",
    "        \n",
    "    - Off-diagonal values indicate misclassifications.\n",
    "        \n",
    "    - **Outcome**:\n",
    "        \n",
    "        - Most predictions are concentrated around the majority class (rating 10.0).\n",
    "        - Significant misclassification occurs for other ratings, reflecting the class imbalance and difficulty in predicting minority classes.\n",
    "\n",
    "---\n",
    "\n",
    "### **Why Accuracy is Low**\n",
    "\n",
    "1. **Class Imbalance**: The dataset has a skewed distribution of ratings, with a high proportion of 10.0 ratings. This biases the model towards the majority class.\n",
    "2. **High Dimensionality**: The model has to process 4,315 features, many of which might be irrelevant or noisy.\n",
    "3. **Complex Multi-Class Problem**: Predicting 10 distinct ratings is inherently challenging, especially when the data distribution is uneven.\n",
    "4. **Limited Feature Usefulness**: Features like `drugName` and `condition` may not have strong predictive power for ratings without additional context."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate 5.16 GiB for an array with shape (4315, 160398) and data type int64",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[28], line 21\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[38;5;66;03m# Apply SMOTE to the training data\u001b[39;00m\n\u001b[0;32m     20\u001b[0m smote \u001b[38;5;241m=\u001b[39m SMOTE(random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m)\n\u001b[1;32m---> 21\u001b[0m X_resampled, y_resampled \u001b[38;5;241m=\u001b[39m \u001b[43msmote\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit_resample\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     23\u001b[0m \u001b[38;5;66;03m# Check the new class distribution\u001b[39;00m\n\u001b[0;32m     24\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mcollections\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Counter\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\imblearn\\base.py:208\u001b[0m, in \u001b[0;36mBaseSampler.fit_resample\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    187\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Resample the dataset.\u001b[39;00m\n\u001b[0;32m    188\u001b[0m \n\u001b[0;32m    189\u001b[0m \u001b[38;5;124;03mParameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    205\u001b[0m \u001b[38;5;124;03m    The corresponding label of `X_resampled`.\u001b[39;00m\n\u001b[0;32m    206\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    207\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[1;32m--> 208\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit_resample\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\imblearn\\base.py:106\u001b[0m, in \u001b[0;36mSamplerMixin.fit_resample\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    104\u001b[0m check_classification_targets(y)\n\u001b[0;32m    105\u001b[0m arrays_transformer \u001b[38;5;241m=\u001b[39m ArraysTransformer(X, y)\n\u001b[1;32m--> 106\u001b[0m X, y, binarize_y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_check_X_y\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    108\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msampling_strategy_ \u001b[38;5;241m=\u001b[39m check_sampling_strategy(\n\u001b[0;32m    109\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msampling_strategy, y, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampling_type\n\u001b[0;32m    110\u001b[0m )\n\u001b[0;32m    112\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fit_resample(X, y)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\imblearn\\base.py:161\u001b[0m, in \u001b[0;36mBaseSampler._check_X_y\u001b[1;34m(self, X, y, accept_sparse)\u001b[0m\n\u001b[0;32m    159\u001b[0m     accept_sparse \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcsr\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcsc\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m    160\u001b[0m y, binarize_y \u001b[38;5;241m=\u001b[39m check_target_type(y, indicate_one_vs_all\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m--> 161\u001b[0m X, y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maccept_sparse\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    162\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m X, y, binarize_y\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\base.py:650\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[1;34m(self, X, y, reset, validate_separately, cast_to_ndarray, **check_params)\u001b[0m\n\u001b[0;32m    648\u001b[0m         y \u001b[38;5;241m=\u001b[39m check_array(y, input_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcheck_y_params)\n\u001b[0;32m    649\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 650\u001b[0m         X, y \u001b[38;5;241m=\u001b[39m \u001b[43mcheck_X_y\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mcheck_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    651\u001b[0m     out \u001b[38;5;241m=\u001b[39m X, y\n\u001b[0;32m    653\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m check_params\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mensure_2d\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mTrue\u001b[39;00m):\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\utils\\validation.py:1301\u001b[0m, in \u001b[0;36mcheck_X_y\u001b[1;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_writeable, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)\u001b[0m\n\u001b[0;32m   1296\u001b[0m         estimator_name \u001b[38;5;241m=\u001b[39m _check_estimator_name(estimator)\n\u001b[0;32m   1297\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   1298\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mestimator_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m requires y to be passed, but the target y is None\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1299\u001b[0m     )\n\u001b[1;32m-> 1301\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[43mcheck_array\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1302\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1303\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maccept_sparse\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1304\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccept_large_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maccept_large_sparse\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1305\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1306\u001b[0m \u001b[43m    \u001b[49m\u001b[43morder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43morder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1307\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1308\u001b[0m \u001b[43m    \u001b[49m\u001b[43mforce_writeable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce_writeable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1309\u001b[0m \u001b[43m    \u001b[49m\u001b[43mforce_all_finite\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce_all_finite\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1310\u001b[0m \u001b[43m    \u001b[49m\u001b[43mensure_2d\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mensure_2d\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1311\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_nd\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mallow_nd\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1312\u001b[0m \u001b[43m    \u001b[49m\u001b[43mensure_min_samples\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mensure_min_samples\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1313\u001b[0m \u001b[43m    \u001b[49m\u001b[43mensure_min_features\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mensure_min_features\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1314\u001b[0m \u001b[43m    \u001b[49m\u001b[43mestimator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1315\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mX\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1316\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1318\u001b[0m y \u001b[38;5;241m=\u001b[39m _check_y(y, multi_output\u001b[38;5;241m=\u001b[39mmulti_output, y_numeric\u001b[38;5;241m=\u001b[39my_numeric, estimator\u001b[38;5;241m=\u001b[39mestimator)\n\u001b[0;32m   1320\u001b[0m check_consistent_length(X, y)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\utils\\validation.py:1012\u001b[0m, in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_writeable, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[0;32m   1010\u001b[0m         array \u001b[38;5;241m=\u001b[39m xp\u001b[38;5;241m.\u001b[39mastype(array, dtype, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m   1011\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1012\u001b[0m         array \u001b[38;5;241m=\u001b[39m \u001b[43m_asarray_with_order\u001b[49m\u001b[43m(\u001b[49m\u001b[43marray\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43morder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43morder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mxp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mxp\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1013\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m ComplexWarning \u001b[38;5;28;01mas\u001b[39;00m complex_warning:\n\u001b[0;32m   1014\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   1015\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mComplex data not supported\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(array)\n\u001b[0;32m   1016\u001b[0m     ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mcomplex_warning\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\utils\\_array_api.py:745\u001b[0m, in \u001b[0;36m_asarray_with_order\u001b[1;34m(array, dtype, order, copy, xp, device)\u001b[0m\n\u001b[0;32m    743\u001b[0m     array \u001b[38;5;241m=\u001b[39m numpy\u001b[38;5;241m.\u001b[39marray(array, order\u001b[38;5;241m=\u001b[39morder, dtype\u001b[38;5;241m=\u001b[39mdtype)\n\u001b[0;32m    744\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 745\u001b[0m     array \u001b[38;5;241m=\u001b[39m numpy\u001b[38;5;241m.\u001b[39masarray(array, order\u001b[38;5;241m=\u001b[39morder, dtype\u001b[38;5;241m=\u001b[39mdtype)\n\u001b[0;32m    747\u001b[0m \u001b[38;5;66;03m# At this point array is a NumPy ndarray. We convert it to an array\u001b[39;00m\n\u001b[0;32m    748\u001b[0m \u001b[38;5;66;03m# container that is consistent with the input's namespace.\u001b[39;00m\n\u001b[0;32m    749\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m xp\u001b[38;5;241m.\u001b[39masarray(array)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\pandas\\core\\generic.py:2152\u001b[0m, in \u001b[0;36mNDFrame.__array__\u001b[1;34m(self, dtype, copy)\u001b[0m\n\u001b[0;32m   2149\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__array__\u001b[39m(\n\u001b[0;32m   2150\u001b[0m     \u001b[38;5;28mself\u001b[39m, dtype: npt\u001b[38;5;241m.\u001b[39mDTypeLike \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m, copy: bool_t \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   2151\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m np\u001b[38;5;241m.\u001b[39mndarray:\n\u001b[1;32m-> 2152\u001b[0m     values \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_values\u001b[49m\n\u001b[0;32m   2153\u001b[0m     arr \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39masarray(values, dtype\u001b[38;5;241m=\u001b[39mdtype)\n\u001b[0;32m   2154\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m   2155\u001b[0m         astype_is_view(values\u001b[38;5;241m.\u001b[39mdtype, arr\u001b[38;5;241m.\u001b[39mdtype)\n\u001b[0;32m   2156\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m using_copy_on_write()\n\u001b[0;32m   2157\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_mgr\u001b[38;5;241m.\u001b[39mis_single_block\n\u001b[0;32m   2158\u001b[0m     ):\n\u001b[0;32m   2159\u001b[0m         \u001b[38;5;66;03m# Check if both conversions can be done without a copy\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\pandas\\core\\frame.py:1127\u001b[0m, in \u001b[0;36mDataFrame._values\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1125\u001b[0m blocks \u001b[38;5;241m=\u001b[39m mgr\u001b[38;5;241m.\u001b[39mblocks\n\u001b[0;32m   1126\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(blocks) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m-> 1127\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m ensure_wrapped_if_datetimelike(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalues\u001b[49m)\n\u001b[0;32m   1129\u001b[0m arr \u001b[38;5;241m=\u001b[39m blocks[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mvalues\n\u001b[0;32m   1130\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m arr\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m   1131\u001b[0m     \u001b[38;5;66;03m# non-2D ExtensionArray\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\pandas\\core\\frame.py:12664\u001b[0m, in \u001b[0;36mDataFrame.values\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m  12590\u001b[0m \u001b[38;5;129m@property\u001b[39m\n\u001b[0;32m  12591\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mvalues\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m np\u001b[38;5;241m.\u001b[39mndarray:\n\u001b[0;32m  12592\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m  12593\u001b[0m \u001b[38;5;124;03m    Return a Numpy representation of the DataFrame.\u001b[39;00m\n\u001b[0;32m  12594\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m  12662\u001b[0m \u001b[38;5;124;03m           ['monkey', nan, None]], dtype=object)\u001b[39;00m\n\u001b[0;32m  12663\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m> 12664\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_mgr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mas_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\pandas\\core\\internals\\managers.py:1694\u001b[0m, in \u001b[0;36mBlockManager.as_array\u001b[1;34m(self, dtype, copy, na_value)\u001b[0m\n\u001b[0;32m   1692\u001b[0m         arr\u001b[38;5;241m.\u001b[39mflags\u001b[38;5;241m.\u001b[39mwriteable \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m   1693\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1694\u001b[0m     arr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_interleave\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mna_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mna_value\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1695\u001b[0m     \u001b[38;5;66;03m# The underlying data was copied within _interleave, so no need\u001b[39;00m\n\u001b[0;32m   1696\u001b[0m     \u001b[38;5;66;03m# to further copy if copy=True or setting na_value\u001b[39;00m\n\u001b[0;32m   1698\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m na_value \u001b[38;5;129;01mis\u001b[39;00m lib\u001b[38;5;241m.\u001b[39mno_default:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\pandas\\core\\internals\\managers.py:1727\u001b[0m, in \u001b[0;36mBlockManager._interleave\u001b[1;34m(self, dtype, na_value)\u001b[0m\n\u001b[0;32m   1724\u001b[0m \u001b[38;5;66;03m# error: Argument 1 to \"ensure_np_dtype\" has incompatible type\u001b[39;00m\n\u001b[0;32m   1725\u001b[0m \u001b[38;5;66;03m# \"Optional[dtype[Any]]\"; expected \"Union[dtype[Any], ExtensionDtype]\"\u001b[39;00m\n\u001b[0;32m   1726\u001b[0m dtype \u001b[38;5;241m=\u001b[39m ensure_np_dtype(dtype)  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n\u001b[1;32m-> 1727\u001b[0m result \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mempty(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mshape, dtype\u001b[38;5;241m=\u001b[39mdtype)\n\u001b[0;32m   1729\u001b[0m itemmask \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mzeros(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m])\n\u001b[0;32m   1731\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m dtype \u001b[38;5;241m==\u001b[39m np\u001b[38;5;241m.\u001b[39mdtype(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mobject\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m na_value \u001b[38;5;129;01mis\u001b[39;00m lib\u001b[38;5;241m.\u001b[39mno_default:\n\u001b[0;32m   1732\u001b[0m     \u001b[38;5;66;03m# much more performant than using to_numpy below\u001b[39;00m\n",
      "\u001b[1;31mMemoryError\u001b[0m: Unable to allocate 5.16 GiB for an array with shape (4315, 160398) and data type int64"
     ]
    }
   ],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split the data into features (X) and target (y)\n",
    "X = train_data_cleaned.drop('rating', axis=1)\n",
    "y = train_data_cleaned['rating']\n",
    "\n",
    "# Train a temporary Random Forest model to get feature importances\n",
    "rf_temp = RandomForestClassifier(n_estimators=10, random_state=42)\n",
    "rf_temp.fit(X, y)\n",
    "\n",
    "# Select top 500 important features\n",
    "import numpy as np\n",
    "feature_importances = rf_temp.feature_importances_\n",
    "top_features = np.argsort(feature_importances)[-500:]  # Adjust the number as needed\n",
    "\n",
    "X_reduced = X.iloc[:, top_features]  # Reduce dataset to top features\n",
    "\n",
    "# Apply SMOTE to the training data\n",
    "smote = SMOTE(random_state=42)\n",
    "X_resampled, y_resampled = smote.fit_resample(X, y)\n",
    "\n",
    "# Check the new class distribution\n",
    "from collections import Counter\n",
    "print(f\"Class distribution before SMOTE: {Counter(y)}\")\n",
    "print(f\"Class distribution after SMOTE: {Counter(y_resampled)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split resampled data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_resampled, y_resampled, test_size=0.2, random_state=42)\n",
    "\n",
    "print(f\"Training Features Shape: {X_train.shape}\")\n",
    "print(f\"Training Target Shape: {y_train.shape}\")\n",
    "print(f\"Test Features Shape: {X_test.shape}\")\n",
    "print(f\"Test Target Shape: {y_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize and train the model\n",
    "rf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = rf.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy: {accuracy:.2f}\")\n",
    "\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
